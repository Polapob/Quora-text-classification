{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "สำเนาของ Quora_summary_github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Polapob/Quora-text-classification/blob/main/%E0%B8%AA%E0%B8%B3%E0%B9%80%E0%B8%99%E0%B8%B2%E0%B8%82%E0%B8%AD%E0%B8%87_Quora_summary_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZdSZBnITITN"
      },
      "source": [
        "import random\n",
        "import copy\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from torchtext import data\n",
        "#import spacy\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "from nltk import word_tokenize\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import torchtext\n",
        "import os \n",
        "\n",
        "# cross validation and metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from textblob import TextBlob\n",
        "from multiprocessing import  Pool\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ8rayq9TUMR"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWf5LRArTcua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd141ec0-4935-4257-f4d2-a5411215da3e"
      },
      "source": [
        "!kaggle competitions download -c quora-insincere-questions-classification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 70% 11.0M/15.8M [00:00<00:00, 36.0MB/s]\n",
            "100% 15.8M/15.8M [00:00<00:00, 45.4MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 89% 49.0M/54.9M [00:01<00:00, 47.5MB/s]\n",
            "100% 54.9M/54.9M [00:01<00:00, 47.3MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/4.09M [00:00<?, ?B/s]\n",
            "100% 4.09M/4.09M [00:00<00:00, 37.3MB/s]\n",
            "Downloading embeddings.zip to /content\n",
            "100% 5.96G/5.96G [02:12<00:00, 27.0MB/s]\n",
            "100% 5.96G/5.96G [02:12<00:00, 48.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTWEeMHpTeJf"
      },
      "source": [
        "! mkdir train\n",
        "! mkdir test1\n",
        "! mkdir submission\n",
        "! mkdir embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmKJ6tmOTfqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518c028b-d25c-4d23-ccd1-25a35b4cc469"
      },
      "source": [
        "! unzip train.csv.zip -d train\n",
        "! unzip test.csv.zip -d test\n",
        "! unzip sample_submission.csv.zip -d submission\n",
        "! unzip embeddings.zip -d embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train/train.csv         \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test/test.csv           \n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: submission/sample_submission.csv  \n",
            "Archive:  embeddings.zip\n",
            "   creating: embedding/GoogleNews-vectors-negative300/\n",
            "   creating: embedding/glove.840B.300d/\n",
            "   creating: embedding/paragram_300_sl999/\n",
            "   creating: embedding/wiki-news-300d-1M/\n",
            "  inflating: embedding/glove.840B.300d/glove.840B.300d.txt  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD94TE7oThJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b84074-743f-4e7e-8245-725ee5e5f986"
      },
      "source": [
        "! unzip embeddings.zip -d embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  embeddings.zip\n",
            "replace embedding/glove.840B.300d/glove.840B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "  inflating: embedding/paragram_300_sl999/README.txt  \n",
            "  inflating: embedding/paragram_300_sl999/paragram_300_sl999.txt  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTwnruTdT45q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a4ca9b-041f-496d-9630-4ac183e67455"
      },
      "source": [
        "! unzip embeddings.zip -d embedding "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  embeddings.zip\n",
            "replace embedding/glove.840B.300d/glove.840B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "  inflating: embedding/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eDVKSdPT5UQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee1dc59-4a84-4504-bd2c-ed126d2cd2a1"
      },
      "source": [
        "! unzip embeddings.zip -d embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  embeddings.zip\n",
            "replace embedding/glove.840B.300d/glove.840B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "  inflating: embedding/wiki-news-300d-1M/wiki-news-300d-1M.vec  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us3IC_-qUGwU"
      },
      "source": [
        "train = pd.read_csv(\"train/train.csv\")\n",
        "test = pd.read_csv(\"test/test.csv\")\n",
        "submission = pd.read_csv(\"submission/sample_submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6PU4UpOUMQG"
      },
      "source": [
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';',  '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        if punct in x:\n",
        "            x = x.replace(punct, f' {punct} ')\n",
        "    return x\n",
        "\n",
        "def clean_numbers(x):\n",
        "    if bool(re.search(r'\\d', x)):\n",
        "        x = re.sub('[0-9]{5,}', '#####', x)\n",
        "        x = re.sub('[0-9]{4}', '####', x)\n",
        "        x = re.sub('[0-9]{3}', '###', x)\n",
        "        x = re.sub('[0-9]{2}', '##', x)\n",
        "        x = re.sub('[0-9]{1}', '#', x)\n",
        "    return x\n",
        "clean_train = train.copy()\n",
        "clean_train[\"question_text\"]= clean_train.question_text.apply(lambda x: clean_text(x))\n",
        "clean_train[\"question_text\"]= clean_train.question_text.apply(lambda x: clean_numbers(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVm1-Em7VLTe"
      },
      "source": [
        "missspell_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
        "                \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \n",
        "                \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
        "                \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
        "                \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \n",
        "                \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
        "                \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\",\n",
        "                \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \n",
        "                \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
        "                \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "                \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
        "                \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
        "                \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\n",
        "                \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \n",
        "                \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\",\n",
        "                \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
        "                \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \n",
        "                \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
        "                \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
        "                \"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n",
        "                \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center',\n",
        "                'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n",
        "                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2',\n",
        "                'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What',\n",
        "                'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much',\n",
        "                'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n",
        "                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis',\n",
        "                'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota',\n",
        "                'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization',\n",
        "                'demonitization': 'demonetization', 'demonetisation': 'demonetization'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJxBbiJiVNRb"
      },
      "source": [
        "def sort_dictionary(list_sentence,lower):\n",
        "  dictionary1 = {}\n",
        "  if lower == False:\n",
        "    for sentence in list_sentence:\n",
        "      for word in sentence.split():\n",
        "        try:\n",
        "          dictionary1[word] += 1\n",
        "        except:\n",
        "          dictionary1[word] = 1\n",
        "    word = [[word,occurrence] for word,occurrence in dictionary1.items()]\n",
        "    word = sorted(word,key = lambda x:x[1],reverse=True)\n",
        "    sort_dict = {}\n",
        "    for i in word:\n",
        "      sort_dict[i[0]] = i[1]\n",
        "  elif lower == True:\n",
        "    for sentence in list_sentence:\n",
        "      for word in sentence.split():\n",
        "        str1 = str(word).lower()\n",
        "        try:\n",
        "          dictionary1[str1] += 1\n",
        "        except:\n",
        "          dictionary1[str1] = 1\n",
        "    word = [[word,occurrence] for word,occurrence in dictionary1.items()]\n",
        "    word = sorted(word,key = lambda x:x[1],reverse=True)\n",
        "    sort_dict = {}\n",
        "    for i in word:\n",
        "      sort_dict[i[0]] = i[1]\n",
        "  return sort_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zDs-cOCmua9",
        "outputId": "8a20e269-29e5-4dd0-ed8f-573c10042c9d"
      },
      "source": [
        "list2 = []\n",
        "\n",
        "for i in range(2):\n",
        "  dict1 = sort_dictionary(clean_train[\"question_text\"].values,lower=False)\n",
        "  print(\"Before improvement\")\n",
        "  print(\"Len missspell dict = \" + str(len(missspell_dict)))\n",
        "  for i in missspell_dict:\n",
        "    try:\n",
        "      str1 = i[0].upper() +i[1:]\n",
        "      if str1 in dict1:\n",
        "        #print(str1 + \" doesn't full clean.\")\n",
        "        r = True\n",
        "      list2.append(str1.lower())\n",
        "    except:\n",
        "      pass\n",
        "  lista = list2[:len(list2)-1]\n",
        "  for i in lista:\n",
        "    try:\n",
        "      str1 = i[0].upper() +i[1:]    \n",
        "      str2 = missspell_dict[i][0].upper() + missspell_dict[i][1:]\n",
        "      missspell_dict[str1] = str2 \n",
        "    except:\n",
        "      pass\n",
        "  print(\"After improvement\")\n",
        "  print(\"Len missspell dict = \" + str(len(missspell_dict)))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before improvement\n",
            "Len missspell dict = 162\n",
            "After improvement\n",
            "Len missspell dict = 303\n",
            "\n",
            "Before improvement\n",
            "Len missspell dict = 303\n",
            "After improvement\n",
            "Len missspell dict = 304\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgC0LgX-kxZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b375eb30-3d9b-41e0-da01-bd9647034c8d"
      },
      "source": [
        "list2 = []\n",
        "for i in missspell_dict:\n",
        "  try:\n",
        "    str1 = i[0].upper() +i[1:]\n",
        "    if str1 in dict1:\n",
        "      #print(str1 + \" doesn't full clean.\")\n",
        "      r = True\n",
        "    list2.append(str1.lower())\n",
        "  except:\n",
        "      pass\n",
        "for i in lista:\n",
        "    try:\n",
        "      str1 = i[0].upper() +i[1:]    \n",
        "      str2 = missspell_dict[i][0].upper() + missspell_dict[i][1:]\n",
        "      missspell_dict[str1] = str2 \n",
        "    except:\n",
        "      print(str1,str2)\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Qoura Youtube \n",
            "Whta Salary\n",
            "Doi Why do\n",
            "Thebest Why do\n",
            "Etherium Penis\n",
            "Qoura Youtube \n",
            "Whta Salary\n",
            "Doi Why do\n",
            "Thebest Why do\n",
            "Etherium Penis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXqf-uyOWRF_"
      },
      "source": [
        "def check_missspell(text):\n",
        "  str_text = str(text)\n",
        "  for i in missspell_dict:\n",
        "    if i in str_text:\n",
        "      str_text = str_text.replace(i,missspell_dict[i])\n",
        "  return str_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWz1oKZbUvDE"
      },
      "source": [
        "clean_train[\"question_text\"] = clean_train[\"question_text\"].apply(lambda x: check_missspell(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz8dO-oUWepM"
      },
      "source": [
        "Start_X = clean_train.question_text.values\n",
        "Start_Y = clean_train.target.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNaJykrnXOhe"
      },
      "source": [
        "list_sentence = Start_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E6MbgggXypn"
      },
      "source": [
        "vocab_dictionary = {}\n",
        "for sentence in list_sentence:\n",
        "  for word in sentence:\n",
        "    try:\n",
        "      vocab_dictionary[word]+=1\n",
        "    except:\n",
        "      vocab_dictionary[word]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8lrEbCxfDq8",
        "outputId": "69d5e7bd-2a3c-4435-da37-f3e701bda485"
      },
      "source": [
        "X = []\n",
        "for i in Start_X:\n",
        "  X.append(str(i))\n",
        "X[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['How did Quebec nationalists see their province as a nation in the ####s ? ',\n",
              " 'Do you have an adopted dog ,  how would you encourage people to adopt and not shop ? ',\n",
              " 'Why does velocity affect time ?  Does velocity affect space geometry ? ',\n",
              " 'How did Otto von Guericke used the Magdeburg hemispheres ? ',\n",
              " 'Can I convert montra helicon D to a mountain bike by just changing the tyres ? ',\n",
              " 'Is Gaza slowly becoming Auschwitz ,  Dachau or Treblinka for Palestinians ? ',\n",
              " 'Why does Quora automatically ban conservative opinions when reported ,  but does not do the same for liberal views ? ',\n",
              " 'Is it crazy if I wash or wipe my groceries off ?  Germs are everywhere . ',\n",
              " 'Is there such a thing as dressing moderately ,  and if so ,  how is that different than dressing modestly ? ',\n",
              " 'Is it just me or have you ever been in this phase wherein you became ignorant to the people you once loved ,  completely disregarding their feelings / lives so you get to have something go your way and feel temporarily at ease .  How did things change ? ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owvR2Vn4GUPp",
        "outputId": "f003d899-abb0-4368-990d-fd1e5b86104c"
      },
      "source": [
        "Start_X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['How did Quebec nationalists see their province as a nation in the ####s ? ',\n",
              "       'Do you have an adopted dog ,  how would you encourage people to adopt and not shop ? ',\n",
              "       'Why does velocity affect time ?  Does velocity affect space geometry ? ',\n",
              "       ..., 'Is foam insulation toxic ? ',\n",
              "       'How can one start a research project based on biochemistry at UG level ? ',\n",
              "       'Who wins in a battle between a Wolverine and a Puma ? '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JHV6wl5XmQ-",
        "outputId": "1a7ed0ce-f2b3-4328-d68d-372c49d40bbf"
      },
      "source": [
        "print(\"Check the number of vocab with lower occurrence \\n\")\n",
        "occurrence = 31\n",
        "dict1 = sort_dictionary(X,lower=False)\n",
        "for i in range(1,occurrence+1):\n",
        "  dict_check = {}\n",
        "  count = 1\n",
        "  for word in dict1:\n",
        "    if dict1[word] > i-1:\n",
        "      dict_check[word] = count\n",
        "      count += 1\n",
        "  print(\"Check word of dictionary that occur more than \" + str(i-1)+\" times.\" +\"\\n\")\n",
        "  print(\"The number of word is \" + str(len(dict_check))+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check the number of vocab with lower occurrence \n",
            "\n",
            "Check word of dictionary that occur more than 0 times.\n",
            "\n",
            "The number of word is 246534\n",
            "\n",
            "Check word of dictionary that occur more than 1 times.\n",
            "\n",
            "The number of word is 110987\n",
            "\n",
            "Check word of dictionary that occur more than 2 times.\n",
            "\n",
            "The number of word is 80043\n",
            "\n",
            "Check word of dictionary that occur more than 3 times.\n",
            "\n",
            "The number of word is 65728\n",
            "\n",
            "Check word of dictionary that occur more than 4 times.\n",
            "\n",
            "The number of word is 56977\n",
            "\n",
            "Check word of dictionary that occur more than 5 times.\n",
            "\n",
            "The number of word is 51003\n",
            "\n",
            "Check word of dictionary that occur more than 6 times.\n",
            "\n",
            "The number of word is 46415\n",
            "\n",
            "Check word of dictionary that occur more than 7 times.\n",
            "\n",
            "The number of word is 42943\n",
            "\n",
            "Check word of dictionary that occur more than 8 times.\n",
            "\n",
            "The number of word is 40178\n",
            "\n",
            "Check word of dictionary that occur more than 9 times.\n",
            "\n",
            "The number of word is 37824\n",
            "\n",
            "Check word of dictionary that occur more than 10 times.\n",
            "\n",
            "The number of word is 35827\n",
            "\n",
            "Check word of dictionary that occur more than 11 times.\n",
            "\n",
            "The number of word is 34162\n",
            "\n",
            "Check word of dictionary that occur more than 12 times.\n",
            "\n",
            "The number of word is 32625\n",
            "\n",
            "Check word of dictionary that occur more than 13 times.\n",
            "\n",
            "The number of word is 31270\n",
            "\n",
            "Check word of dictionary that occur more than 14 times.\n",
            "\n",
            "The number of word is 30062\n",
            "\n",
            "Check word of dictionary that occur more than 15 times.\n",
            "\n",
            "The number of word is 28948\n",
            "\n",
            "Check word of dictionary that occur more than 16 times.\n",
            "\n",
            "The number of word is 27929\n",
            "\n",
            "Check word of dictionary that occur more than 17 times.\n",
            "\n",
            "The number of word is 26961\n",
            "\n",
            "Check word of dictionary that occur more than 18 times.\n",
            "\n",
            "The number of word is 26164\n",
            "\n",
            "Check word of dictionary that occur more than 19 times.\n",
            "\n",
            "The number of word is 25396\n",
            "\n",
            "Check word of dictionary that occur more than 20 times.\n",
            "\n",
            "The number of word is 24677\n",
            "\n",
            "Check word of dictionary that occur more than 21 times.\n",
            "\n",
            "The number of word is 24035\n",
            "\n",
            "Check word of dictionary that occur more than 22 times.\n",
            "\n",
            "The number of word is 23469\n",
            "\n",
            "Check word of dictionary that occur more than 23 times.\n",
            "\n",
            "The number of word is 22886\n",
            "\n",
            "Check word of dictionary that occur more than 24 times.\n",
            "\n",
            "The number of word is 22363\n",
            "\n",
            "Check word of dictionary that occur more than 25 times.\n",
            "\n",
            "The number of word is 21882\n",
            "\n",
            "Check word of dictionary that occur more than 26 times.\n",
            "\n",
            "The number of word is 21418\n",
            "\n",
            "Check word of dictionary that occur more than 27 times.\n",
            "\n",
            "The number of word is 20968\n",
            "\n",
            "Check word of dictionary that occur more than 28 times.\n",
            "\n",
            "The number of word is 20493\n",
            "\n",
            "Check word of dictionary that occur more than 29 times.\n",
            "\n",
            "The number of word is 20055\n",
            "\n",
            "Check word of dictionary that occur more than 30 times.\n",
            "\n",
            "The number of word is 19673\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k7-fF4UZzUt"
      },
      "source": [
        "First We use based Model to predict outcome. So we want case unsensitive word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCjN9wW6ZQNg"
      },
      "source": [
        "list_sentence = []\n",
        "for i in Start_X:\n",
        "  list_word = []\n",
        "  for j in i.split():\n",
        "    list_word.append(j.lower())\n",
        "  list_sentence.append(list_word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zuEUuA_avJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeeb8cbf-1cdb-45f6-c47c-da014fc91b59"
      },
      "source": [
        "list_sentence[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['how',\n",
              "  'did',\n",
              "  'quebec',\n",
              "  'nationalists',\n",
              "  'see',\n",
              "  'their',\n",
              "  'province',\n",
              "  'as',\n",
              "  'a',\n",
              "  'nation',\n",
              "  'in',\n",
              "  'the',\n",
              "  '####s',\n",
              "  '?'],\n",
              " ['do',\n",
              "  'you',\n",
              "  'have',\n",
              "  'an',\n",
              "  'adopted',\n",
              "  'dog',\n",
              "  ',',\n",
              "  'how',\n",
              "  'would',\n",
              "  'you',\n",
              "  'encourage',\n",
              "  'people',\n",
              "  'to',\n",
              "  'adopt',\n",
              "  'and',\n",
              "  'not',\n",
              "  'shop',\n",
              "  '?'],\n",
              " ['why',\n",
              "  'does',\n",
              "  'velocity',\n",
              "  'affect',\n",
              "  'time',\n",
              "  '?',\n",
              "  'does',\n",
              "  'velocity',\n",
              "  'affect',\n",
              "  'space',\n",
              "  'geometry',\n",
              "  '?'],\n",
              " ['how',\n",
              "  'did',\n",
              "  'otto',\n",
              "  'von',\n",
              "  'guericke',\n",
              "  'used',\n",
              "  'the',\n",
              "  'magdeburg',\n",
              "  'hemispheres',\n",
              "  '?'],\n",
              " ['can',\n",
              "  'i',\n",
              "  'convert',\n",
              "  'montra',\n",
              "  'helicon',\n",
              "  'd',\n",
              "  'to',\n",
              "  'a',\n",
              "  'mountain',\n",
              "  'bike',\n",
              "  'by',\n",
              "  'just',\n",
              "  'changing',\n",
              "  'the',\n",
              "  'tyres',\n",
              "  '?'],\n",
              " ['is',\n",
              "  'gaza',\n",
              "  'slowly',\n",
              "  'becoming',\n",
              "  'auschwitz',\n",
              "  ',',\n",
              "  'dachau',\n",
              "  'or',\n",
              "  'treblinka',\n",
              "  'for',\n",
              "  'palestinians',\n",
              "  '?'],\n",
              " ['why',\n",
              "  'does',\n",
              "  'quora',\n",
              "  'automatically',\n",
              "  'ban',\n",
              "  'conservative',\n",
              "  'opinions',\n",
              "  'when',\n",
              "  'reported',\n",
              "  ',',\n",
              "  'but',\n",
              "  'does',\n",
              "  'not',\n",
              "  'do',\n",
              "  'the',\n",
              "  'same',\n",
              "  'for',\n",
              "  'liberal',\n",
              "  'views',\n",
              "  '?'],\n",
              " ['is',\n",
              "  'it',\n",
              "  'crazy',\n",
              "  'if',\n",
              "  'i',\n",
              "  'wash',\n",
              "  'or',\n",
              "  'wipe',\n",
              "  'my',\n",
              "  'groceries',\n",
              "  'off',\n",
              "  '?',\n",
              "  'germs',\n",
              "  'are',\n",
              "  'everywhere',\n",
              "  '.'],\n",
              " ['is',\n",
              "  'there',\n",
              "  'such',\n",
              "  'a',\n",
              "  'thing',\n",
              "  'as',\n",
              "  'dressing',\n",
              "  'moderately',\n",
              "  ',',\n",
              "  'and',\n",
              "  'if',\n",
              "  'so',\n",
              "  ',',\n",
              "  'how',\n",
              "  'is',\n",
              "  'that',\n",
              "  'different',\n",
              "  'than',\n",
              "  'dressing',\n",
              "  'modestly',\n",
              "  '?'],\n",
              " ['is',\n",
              "  'it',\n",
              "  'just',\n",
              "  'me',\n",
              "  'or',\n",
              "  'have',\n",
              "  'you',\n",
              "  'ever',\n",
              "  'been',\n",
              "  'in',\n",
              "  'this',\n",
              "  'phase',\n",
              "  'wherein',\n",
              "  'you',\n",
              "  'became',\n",
              "  'ignorant',\n",
              "  'to',\n",
              "  'the',\n",
              "  'people',\n",
              "  'you',\n",
              "  'once',\n",
              "  'loved',\n",
              "  ',',\n",
              "  'completely',\n",
              "  'disregarding',\n",
              "  'their',\n",
              "  'feelings',\n",
              "  '/',\n",
              "  'lives',\n",
              "  'so',\n",
              "  'you',\n",
              "  'get',\n",
              "  'to',\n",
              "  'have',\n",
              "  'something',\n",
              "  'go',\n",
              "  'your',\n",
              "  'way',\n",
              "  'and',\n",
              "  'feel',\n",
              "  'temporarily',\n",
              "  'at',\n",
              "  'ease',\n",
              "  '.',\n",
              "  'how',\n",
              "  'did',\n",
              "  'things',\n",
              "  'change',\n",
              "  '?'],\n",
              " ['what', 'can', 'you', 'say', 'about', 'feminism', '?'],\n",
              " ['how', 'were', 'the', 'calgary', 'flames', 'founded', '?'],\n",
              " ['what',\n",
              "  'is',\n",
              "  'the',\n",
              "  'dumbest',\n",
              "  ',',\n",
              "  'yet',\n",
              "  'possibly',\n",
              "  'true',\n",
              "  'explanation',\n",
              "  'for',\n",
              "  'trump',\n",
              "  'being',\n",
              "  'elected',\n",
              "  '?'],\n",
              " ['can',\n",
              "  'we',\n",
              "  'use',\n",
              "  'our',\n",
              "  'external',\n",
              "  'hard',\n",
              "  'disk',\n",
              "  'as',\n",
              "  'a',\n",
              "  'os',\n",
              "  'as',\n",
              "  'well',\n",
              "  'as',\n",
              "  'for',\n",
              "  'data',\n",
              "  'storage',\n",
              "  '.',\n",
              "  'will',\n",
              "  'the',\n",
              "  'data',\n",
              "  'be',\n",
              "  'affected',\n",
              "  '?'],\n",
              " ['i',\n",
              "  'am',\n",
              "  '##',\n",
              "  ',',\n",
              "  'living',\n",
              "  'at',\n",
              "  'home',\n",
              "  'and',\n",
              "  'have',\n",
              "  'no',\n",
              "  'boyfriend',\n",
              "  '.',\n",
              "  'i',\n",
              "  'would',\n",
              "  'love',\n",
              "  'a',\n",
              "  'boyfriend',\n",
              "  'and',\n",
              "  'my',\n",
              "  'own',\n",
              "  'home',\n",
              "  '.',\n",
              "  'how',\n",
              "  'can',\n",
              "  'i',\n",
              "  'progress',\n",
              "  'my',\n",
              "  'situation',\n",
              "  '?'],\n",
              " ['what',\n",
              "  'do',\n",
              "  'you',\n",
              "  'know',\n",
              "  'about',\n",
              "  'bram',\n",
              "  'fischer',\n",
              "  'and',\n",
              "  'the',\n",
              "  'rivonia',\n",
              "  'trial',\n",
              "  '?'],\n",
              " ['how',\n",
              "  'difficult',\n",
              "  'is',\n",
              "  'it',\n",
              "  'to',\n",
              "  'find',\n",
              "  'a',\n",
              "  'good',\n",
              "  'instructor',\n",
              "  'to',\n",
              "  'take',\n",
              "  'a',\n",
              "  'class',\n",
              "  'near',\n",
              "  'you',\n",
              "  '?'],\n",
              " ['have', 'you', 'licked', 'the', 'skin', 'of', 'a', 'corpse', '?'],\n",
              " ['do',\n",
              "  'you',\n",
              "  'think',\n",
              "  'amazon',\n",
              "  'will',\n",
              "  'adopt',\n",
              "  'an',\n",
              "  'in',\n",
              "  'house',\n",
              "  'approach',\n",
              "  'to',\n",
              "  'manufacturing',\n",
              "  'similar',\n",
              "  'to',\n",
              "  'the',\n",
              "  'tesla',\n",
              "  'or',\n",
              "  'space',\n",
              "  'x',\n",
              "  'business',\n",
              "  'models',\n",
              "  '?'],\n",
              " ['how',\n",
              "  'many',\n",
              "  'baronies',\n",
              "  'might',\n",
              "  'exist',\n",
              "  'within',\n",
              "  'a',\n",
              "  'county',\n",
              "  'palatine',\n",
              "  '?']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgY7yFUyiYxe"
      },
      "source": [
        "dict2[\"what's\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-DRRO5rYnoF",
        "outputId": "ee5b3e4a-0444-4aa5-c779-d729e7f35a25"
      },
      "source": [
        "print(\"Check the number of vocab with lower occurrence \\n\")\n",
        "occurrence = 31\n",
        "dict2 = sort_dictionary(X,lower=True)\n",
        "for i in range(1,occurrence+1):\n",
        "  dict_check = {}\n",
        "  count = 1\n",
        "  for word in dict2:\n",
        "    if dict2[word] > i-1:\n",
        "      dict_check[word] = count\n",
        "      count += 1\n",
        "  print(\"Check word of dictionary that occur more than \" + str(i-1)+\" times.\" +\"\\n\")\n",
        "  print(\"The number of word is \" + str(len(dict_check))+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check the number of vocab with lower occurrence \n",
            "\n",
            "Check word of dictionary that occur more than 0 times.\n",
            "\n",
            "The number of word is 202942\n",
            "\n",
            "Check word of dictionary that occur more than 1 times.\n",
            "\n",
            "The number of word is 94456\n",
            "\n",
            "Check word of dictionary that occur more than 2 times.\n",
            "\n",
            "The number of word is 69278\n",
            "\n",
            "Check word of dictionary that occur more than 3 times.\n",
            "\n",
            "The number of word is 57695\n",
            "\n",
            "Check word of dictionary that occur more than 4 times.\n",
            "\n",
            "The number of word is 50488\n",
            "\n",
            "Check word of dictionary that occur more than 5 times.\n",
            "\n",
            "The number of word is 45538\n",
            "\n",
            "Check word of dictionary that occur more than 6 times.\n",
            "\n",
            "The number of word is 41700\n",
            "\n",
            "Check word of dictionary that occur more than 7 times.\n",
            "\n",
            "The number of word is 38739\n",
            "\n",
            "Check word of dictionary that occur more than 8 times.\n",
            "\n",
            "The number of word is 36288\n",
            "\n",
            "Check word of dictionary that occur more than 9 times.\n",
            "\n",
            "The number of word is 34247\n",
            "\n",
            "Check word of dictionary that occur more than 10 times.\n",
            "\n",
            "The number of word is 32519\n",
            "\n",
            "Check word of dictionary that occur more than 11 times.\n",
            "\n",
            "The number of word is 31104\n",
            "\n",
            "Check word of dictionary that occur more than 12 times.\n",
            "\n",
            "The number of word is 29792\n",
            "\n",
            "Check word of dictionary that occur more than 13 times.\n",
            "\n",
            "The number of word is 28613\n",
            "\n",
            "Check word of dictionary that occur more than 14 times.\n",
            "\n",
            "The number of word is 27617\n",
            "\n",
            "Check word of dictionary that occur more than 15 times.\n",
            "\n",
            "The number of word is 26585\n",
            "\n",
            "Check word of dictionary that occur more than 16 times.\n",
            "\n",
            "The number of word is 25683\n",
            "\n",
            "Check word of dictionary that occur more than 17 times.\n",
            "\n",
            "The number of word is 24897\n",
            "\n",
            "Check word of dictionary that occur more than 18 times.\n",
            "\n",
            "The number of word is 24144\n",
            "\n",
            "Check word of dictionary that occur more than 19 times.\n",
            "\n",
            "The number of word is 23459\n",
            "\n",
            "Check word of dictionary that occur more than 20 times.\n",
            "\n",
            "The number of word is 22871\n",
            "\n",
            "Check word of dictionary that occur more than 21 times.\n",
            "\n",
            "The number of word is 22234\n",
            "\n",
            "Check word of dictionary that occur more than 22 times.\n",
            "\n",
            "The number of word is 21728\n",
            "\n",
            "Check word of dictionary that occur more than 23 times.\n",
            "\n",
            "The number of word is 21205\n",
            "\n",
            "Check word of dictionary that occur more than 24 times.\n",
            "\n",
            "The number of word is 20741\n",
            "\n",
            "Check word of dictionary that occur more than 25 times.\n",
            "\n",
            "The number of word is 20335\n",
            "\n",
            "Check word of dictionary that occur more than 26 times.\n",
            "\n",
            "The number of word is 19927\n",
            "\n",
            "Check word of dictionary that occur more than 27 times.\n",
            "\n",
            "The number of word is 19545\n",
            "\n",
            "Check word of dictionary that occur more than 28 times.\n",
            "\n",
            "The number of word is 19186\n",
            "\n",
            "Check word of dictionary that occur more than 29 times.\n",
            "\n",
            "The number of word is 18797\n",
            "\n",
            "Check word of dictionary that occur more than 30 times.\n",
            "\n",
            "The number of word is 18440\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IU8vpUyoptt"
      },
      "source": [
        "dict1 = sort_dictionary(X,lower=False)\n",
        "dict2 = sort_dictionary(X,lower=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59KbAkdTfA1o"
      },
      "source": [
        "number_of_word = 100000\n",
        "dict_use = {\"OOV\":0}\n",
        "count = 1\n",
        "for i in dict1:\n",
        "  count +=1\n",
        "  dict_use[i] =len(dict_use)\n",
        "  if count ==100000:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaLBjG1Sek5h"
      },
      "source": [
        "max_word_per_sentence = 70\n",
        "padding = []\n",
        "for sentence in X:\n",
        "  list2 =[]\n",
        "  for word in sentence.split():\n",
        "    try:\n",
        "      list2.append(dict_use[word])\n",
        "    except:\n",
        "      list2.append(dict_use[\"OOV\"])\n",
        "  padding.append(list2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWLu-XYPaKEZ"
      },
      "source": [
        "max_word_per_sentence = 70\n",
        "padding_maxword = []\n",
        "for i in padding:\n",
        "  sentence  = i.copy()\n",
        "  if len(i) > max_word_per_sentence:\n",
        "    padding_maxword.append(sentence[:max_word_per_sentence])\n",
        "  else:\n",
        "    for i in range(max_word_per_sentence-len(i)):\n",
        "      sentence.append(0)\n",
        "    padding_maxword.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGHxhOAmJRF6",
        "outputId": "07f72e90-9474-4064-a6e4-72d6df62fada"
      },
      "source": [
        "for i in padding_maxword[:10]:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10, 66, 6949, 8033, 183, 68, 6664, 42, 5, 1266, 6, 2, 1564, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[58, 16, 26, 36, 3871, 522, 12, 79, 46, 16, 3640, 44, 4, 3067, 11, 29, 1899, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[17, 32, 2023, 390, 89, 1, 90, 2023, 390, 515, 5593, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[10, 66, 14194, 10404, 56978, 139, 2, 42944, 30063, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[48, 9, 1119, 65729, 0, 1227, 4, 5, 4045, 1588, 56, 120, 1485, 2, 10057, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[21, 9305, 3899, 778, 20494, 12, 56979, 27, 0, 15, 2626, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[17, 32, 125, 2568, 1697, 1633, 2445, 51, 4337, 12, 81, 32, 29, 13, 2, 159, 15, 1278, 917, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[21, 18, 1997, 37, 9, 3002, 27, 5887, 23, 13288, 247, 1, 80044, 14, 3730, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[21, 47, 231, 5, 212, 42, 6745, 20495, 12, 11, 37, 65, 12, 79, 7, 22, 151, 88, 6745, 26962, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[21, 18, 120, 67, 27, 26, 16, 112, 135, 6, 80, 2304, 16045, 16, 1392, 3166, 4, 2, 44, 16, 713, 1723, 12, 914, 24036, 68, 1083, 57, 1100, 65, 16, 38, 4, 26, 220, 129, 34, 99, 11, 121, 7082, 53, 6720, 19, 10, 66, 164, 190, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn8UFM8HHlx0",
        "outputId": "7518ae77-4654-4d9b-a250-f244eb994f25"
      },
      "source": [
        "for i in range(len(padding_maxword[:40])):\n",
        "  print(padding_maxword[i])\n",
        "  print(X[i])\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10, 66, 6949, 8033, 183, 68, 6664, 42, 5, 1266, 6, 2, 1564, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How did Quebec nationalists see their province as a nation in the ####s ? \n",
            "\n",
            "[58, 16, 26, 36, 3871, 522, 12, 79, 46, 16, 3640, 44, 4, 3067, 11, 29, 1899, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Do you have an adopted dog ,  how would you encourage people to adopt and not shop ? \n",
            "\n",
            "[17, 32, 2023, 390, 89, 1, 90, 2023, 390, 515, 5593, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Why does velocity affect time ?  Does velocity affect space geometry ? \n",
            "\n",
            "[10, 66, 14194, 10404, 56978, 139, 2, 42944, 30063, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How did Otto von Guericke used the Magdeburg hemispheres ? \n",
            "\n",
            "[48, 9, 1119, 65729, 0, 1227, 4, 5, 4045, 1588, 56, 120, 1485, 2, 10057, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Can I convert montra helicon D to a mountain bike by just changing the tyres ? \n",
            "\n",
            "[21, 9305, 3899, 778, 20494, 12, 56979, 27, 0, 15, 2626, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Is Gaza slowly becoming Auschwitz ,  Dachau or Treblinka for Palestinians ? \n",
            "\n",
            "[17, 32, 125, 2568, 1697, 1633, 2445, 51, 4337, 12, 81, 32, 29, 13, 2, 159, 15, 1278, 917, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Why does Quora automatically ban conservative opinions when reported ,  but does not do the same for liberal views ? \n",
            "\n",
            "[21, 18, 1997, 37, 9, 3002, 27, 5887, 23, 13288, 247, 1, 80044, 14, 3730, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Is it crazy if I wash or wipe my groceries off ?  Germs are everywhere . \n",
            "\n",
            "[21, 47, 231, 5, 212, 42, 6745, 20495, 12, 11, 37, 65, 12, 79, 7, 22, 151, 88, 6745, 26962, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Is there such a thing as dressing moderately ,  and if so ,  how is that different than dressing modestly ? \n",
            "\n",
            "[21, 18, 120, 67, 27, 26, 16, 112, 135, 6, 80, 2304, 16045, 16, 1392, 3166, 4, 2, 44, 16, 713, 1723, 12, 914, 24036, 68, 1083, 57, 1100, 65, 16, 38, 4, 26, 220, 129, 34, 99, 11, 121, 7082, 53, 6720, 19, 10, 66, 164, 190, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Is it just me or have you ever been in this phase wherein you became ignorant to the people you once loved ,  completely disregarding their feelings / lives so you get to have something go your way and feel temporarily at ease .  How did things change ? \n",
            "\n",
            "[3, 20, 16, 177, 54, 2779, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "What can you say about feminism ? \n",
            "\n",
            "[10, 115, 2, 14037, 31271, 3175, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How were the Calgary Flames founded ? \n",
            "\n",
            "[3, 7, 2, 7111, 12, 692, 2627, 229, 2643, 15, 143, 106, 2935, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "What is the dumbest ,  yet possibly true explanation for Trump being elected ? \n",
            "\n",
            "[48, 60, 95, 160, 2573, 315, 5119, 42, 5, 2688, 42, 322, 42, 15, 291, 2718, 19, 61, 2, 291, 28, 1640, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Can we use our external hard disk as a OS as well as for data storage . will the data be affected ? \n",
            "\n",
            "[9, 73, 43, 12, 333, 53, 268, 11, 26, 132, 516, 19, 9, 46, 162, 5, 516, 11, 23, 210, 268, 19, 10, 20, 9, 3096, 23, 1014, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "I am ## ,  living at home and have no boyfriend .  I would love a boyfriend and my own home .  How can I progress my situation ? \n",
            "\n",
            "[3, 13, 16, 101, 54, 34163, 24037, 11, 2, 0, 25397, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "What do you know about Bram Fischer and the Rivonia Trial ? \n",
            "\n",
            "[10, 619, 7, 18, 4, 114, 5, 63, 9059, 4, 109, 5, 244, 899, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How difficult is it to find a good instructor to take a class near you ? \n",
            "\n",
            "[238, 16, 12840, 2, 649, 8, 5, 15631, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Have you licked the skin of a corpse ? \n",
            "\n",
            "[58, 16, 84, 670, 61, 3067, 36, 6, 443, 1241, 4, 1690, 566, 4, 2, 2527, 27, 4374, 1372, 166, 2221, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Do you think Amazon will adopt an in house approach to manufacturing similar to the Tesla or Space X business models ? \n",
            "\n",
            "[10, 86, 80045, 853, 592, 767, 5, 6534, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How many baronies might exist within a county palatine ? \n",
            "\n",
            "[10, 9, 101, 1309, 5, 206, 147, 273, 191, 163, 191, 24, 67, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How I know whether a girl had done sex before sex with me ? \n",
            "\n",
            "[10, 13, 9, 117, 5, 735, 9246, 340, 6, 23, 775, 262, 11, 6, 23, 614, 94, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How do I become a fast learner both in my professional career and in my personal life ? \n",
            "\n",
            "[286, 2, 384, 468, 117, 2, 1628, 6173, 6, 2, 127, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Has the United States become the largest dictatorship in the world ? \n",
            "\n",
            "[3, 7, 2, 4338, 5767, 16, 101, 8, 12, 26, 4809, 27, 26, 4826, 6, 2, 681, 8, 1853, 22, 82, 132, 2643, 6, 613, 8, 604, 553, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "What is the strangest phenomenon you know of ,  have witnessed or have generated in the area of electronics that has no explanation in terms of modern physics ? \n",
            "\n",
            "[116, 9, 530, 23, 278, 11, 114, 161, 928, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Should I leave my friends and find new ones ? \n",
            "\n",
            "[48, 16, 78, 670, 6950, 5511, 1063, 6, 2, 3625, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Can you make Amazon Alexa trigger events in the browser ? \n",
            "\n",
            "[17, 26, 29, 215, 13878, 256, 112, 1209, 15, 5, 454, 30064, 381, 1, 3, 3463, 111, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Why have not two democracies never ever went for a full fledged war ?  What stops them ? \n",
            "\n",
            "[10, 20, 9, 308, 930, 6, 31, 428, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How can I top CBSE in # months ? \n",
            "\n",
            "[3, 50, 9, 101, 163, 1886, 56980, 11, 235, 2, 80046, 12608, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "What should I know before visiting Mcleodganj and doing the Triund trek ? \n",
            "\n",
            "[10, 13, 604, 528, 9912, 944, 3076, 4, 1394, 10631, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How do modern military submarines reduce noise to achieve stealth ? \n",
            "\n",
            "[52, 2377, 14, 83, 26963, 4, 68, 288, 1, 4914, 649, 2377, 27, 462, 649, 2377, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Which babies are more sweeter to their parents ?  Dark skin babies or light skin babies ? \n",
            "\n",
            "[10, 20, 9, 749, 264, 4456, 110, 14, 85, 154, 23, 2053, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How can I remove black heads which are all over my nose ? \n",
            "\n",
            "[69, 31272, 14, 859, 56, 1434, 80047, 12, 32, 310, 21419, 26, 1555, 2508, 57, 4396, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "If lightsabers are created by individual wielders ,  does each saber have unique powers / abilities ? \n",
            "\n",
            "[21, 202, 150, 185, 8206, 11229, 1, 21, 18, 402, 301, 6, 71, 1, 172, 47, 28, 775, 392, 15, 8206, 11229, 4157, 6, 71, 35, 43, 35, 43, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Is anyone still using Visual Basic ?  Is it worth learning in #### ?  Would there be professional jobs for Visual Basic programmers in #### - ## - ## ? \n",
            "\n",
            "[3, 7, 34164, 20056, 85, 54, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "What is Sykes Enterprises all about ? \n",
            "\n",
            "[21, 47, 59, 1010, 2066, 87, 2, 239, 8, 7318, 57, 0, 11, 2, 7961, 12493, 11, 1509, 6, 31273, 27, 17747, 21420, 40, 15, 27930, 2344, 6, 1541, 41, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Is there any clear relations between the number of nodes / DOFs and the computational performances and requirements in FEA or CFD analyses  ( for ANSYS solutions in particular )  ? \n",
            "\n",
            "[17, 23, 1652, 150, 7, 3675, 466, 2286, 43, 12, 71, 11, 9, 13, 29, 26, 5465, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Why my package still is ISC since May ## , #### and I do not have updated ? \n",
            "\n",
            "[3, 32, 422, 18945, 138, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "What does great wit mean ? \n",
            "\n",
            "[169, 34, 228, 276, 24, 65730, 12, 62, 13, 16, 1126, 65730, 66, 123, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "In your experience working with Realtors ,  what do you wish Realtors did better ? \n",
            "\n",
            "[10, 13, 9, 38, 891, 56, 812, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "How do I get charge by contact ? \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzRJsYMuhJww"
      },
      "source": [
        "Train-test-split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuwmuekMefQz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_validation,Y_train,Y_validation = train_test_split(np.array(padding_maxword),clean_train.target.values,test_size=0.15,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbmjDCXIhNXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327c7058-0e42-4874-932b-01636d372420"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "# This is called to clear the original model session in order to use TensorBoard\n",
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "# Path to save model parameters\n",
        "\n",
        "int_sequences_input = keras.Input(shape=(70,), dtype=float)\n",
        "embedded_sequences = layers.Embedding(100000,300,trainable=True)(int_sequences_input)\n",
        "x = layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(embedded_sequences)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "preds = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model2 = keras.Model(int_sequences_input, preds)\n",
        "model2.compile(optimizer=keras.optimizers.Adam(),loss='binary_crossentropy',metrics=['acc'])\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 70)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 70, 300)           30000000  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 70, 256)           440320    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 30,456,833\n",
            "Trainable params: 30,456,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqP05xj_hjNt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "bf2d4eb9-c7fe-46ef-c992-e447d4714172"
      },
      "source": [
        "model2.fit(X_train,Y_train, validation_data=(X_validation,Y_validation),\n",
        "          epochs=3, batch_size=512,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " 240/2169 [==>...........................] - ETA: 11:00 - loss: 0.2385 - acc: 0.9322"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-703f329f396d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model2.fit(X_train,Y_train, validation_data=(X_validation,Y_validation),\n\u001b[0;32m----> 2\u001b[0;31m           epochs=3, batch_size=512,verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkELDEBHDz6o"
      },
      "source": [
        "y_predict1 = model2.predict(X_validation)\n",
        "y_predict = pd.DataFrame(y_predict1,columns=[\"Y_prediction\"])\n",
        "y_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNhkqV-FEgoC"
      },
      "source": [
        "y_predict[\"Y_prediction\"] = np.where(y_predict.Y_prediction.values>=0.5,1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReT73Dr6F2Gf"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1score = f1_score(Y_validation,y_predict.Y_prediction.values)\n",
        "print(\"F1_score of the model is \",f1score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlJOCacDGev-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iL92MHnGfoj"
      },
      "source": [
        "Load glove word embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqZCjzGTGmuT"
      },
      "source": [
        "Create new word index for Glove embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrPgYWUwhnrX"
      },
      "source": [
        "crate_dict_for_glove = sort_dictionary(X,lower=False)\n",
        "max_word_per_sentence = 70\n",
        "number_of_word = 100000\n",
        "dict_glove = {\"OOV\":0}\n",
        "count = 1\n",
        "for i in crate_dict_for_glove:\n",
        "  count +=1\n",
        "  dict_glove[i] =len(dict_glove)\n",
        "  if count ==100000:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfSECEgAIw1P"
      },
      "source": [
        "glove_padding = []\n",
        "for sentence in X:\n",
        "  list2 =[]\n",
        "  for word in sentence.split():\n",
        "    try:\n",
        "      list2.append(dict_glove[word])\n",
        "    except:\n",
        "      list2.append(dict_glove[\"OOV\"])\n",
        "  glove_padding.append(list2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjmsU71HJ6cL",
        "outputId": "947168cd-24f1-4007-c58e-a8fab10645ac"
      },
      "source": [
        "for j in glove_padding[:20]:\n",
        "  print(j)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10, 66, 6949, 8033, 183, 68, 6664, 42, 5, 1266, 6, 2, 1564, 1]\n",
            "[58, 16, 26, 36, 3871, 522, 12, 79, 46, 16, 3640, 44, 4, 3067, 11, 29, 1899, 1]\n",
            "[17, 32, 2023, 390, 89, 1, 90, 2023, 390, 515, 5593, 1]\n",
            "[10, 66, 14194, 10404, 56978, 139, 2, 42944, 30063, 1]\n",
            "[48, 9, 1119, 65729, 0, 1227, 4, 5, 4045, 1588, 56, 120, 1485, 2, 10057, 1]\n",
            "[21, 9305, 3899, 778, 20494, 12, 56979, 27, 0, 15, 2626, 1]\n",
            "[17, 32, 125, 2568, 1697, 1633, 2445, 51, 4337, 12, 81, 32, 29, 13, 2, 159, 15, 1278, 917, 1]\n",
            "[21, 18, 1997, 37, 9, 3002, 27, 5887, 23, 13288, 247, 1, 80044, 14, 3730, 19]\n",
            "[21, 47, 231, 5, 212, 42, 6745, 20495, 12, 11, 37, 65, 12, 79, 7, 22, 151, 88, 6745, 26962, 1]\n",
            "[21, 18, 120, 67, 27, 26, 16, 112, 135, 6, 80, 2304, 16045, 16, 1392, 3166, 4, 2, 44, 16, 713, 1723, 12, 914, 24036, 68, 1083, 57, 1100, 65, 16, 38, 4, 26, 220, 129, 34, 99, 11, 121, 7082, 53, 6720, 19, 10, 66, 164, 190, 1]\n",
            "[3, 20, 16, 177, 54, 2779, 1]\n",
            "[10, 115, 2, 14037, 31271, 3175, 1]\n",
            "[3, 7, 2, 7111, 12, 692, 2627, 229, 2643, 15, 143, 106, 2935, 1]\n",
            "[48, 60, 95, 160, 2573, 315, 5119, 42, 5, 2688, 42, 322, 42, 15, 291, 2718, 19, 61, 2, 291, 28, 1640, 1]\n",
            "[9, 73, 43, 12, 333, 53, 268, 11, 26, 132, 516, 19, 9, 46, 162, 5, 516, 11, 23, 210, 268, 19, 10, 20, 9, 3096, 23, 1014, 1]\n",
            "[3, 13, 16, 101, 54, 34163, 24037, 11, 2, 0, 25397, 1]\n",
            "[10, 619, 7, 18, 4, 114, 5, 63, 9059, 4, 109, 5, 244, 899, 16, 1]\n",
            "[238, 16, 12840, 2, 649, 8, 5, 15631, 1]\n",
            "[58, 16, 84, 670, 61, 3067, 36, 6, 443, 1241, 4, 1690, 566, 4, 2, 2527, 27, 4374, 1372, 166, 2221, 1]\n",
            "[10, 86, 80045, 853, 592, 767, 5, 6534, 0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XQtqk09LybB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PrjoSTyI31E"
      },
      "source": [
        "padding_maxword_for_glove = []\n",
        "for i in glove_padding:\n",
        "  sentence  = i.copy()\n",
        "  if len(i) > max_word_per_sentence:\n",
        "    padding_maxword_for_glove.append(sentence[:max_word_per_sentence])\n",
        "  else:\n",
        "    for i in range(max_word_per_sentence-len(i)):\n",
        "      sentence.append(0)\n",
        "    padding_maxword_for_glove.append(sentence)\n",
        "X_train,X_validation,Y_train,Y_validation = train_test_split(np.array(padding_maxword_for_glove),clean_train.target.values,test_size=0.15,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9A_5aQpXlOX",
        "outputId": "c5b839c8-ddc3-4c97-a244-512af4123bab"
      },
      "source": [
        "for i in padding_maxword_for_glove[:2]:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10, 66, 6949, 8033, 183, 68, 6664, 42, 5, 1266, 6, 2, 1564, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[58, 16, 26, 36, 3871, 522, 12, 79, 46, 16, 3640, 44, 4, 3067, 11, 29, 1899, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o824QLu4PuMi"
      },
      "source": [
        "def load_glove_fast(word_index, max_words, embed_size=300):\n",
        "    EMBEDDING_FILE = 'embedding/glove.840B.300d/glove.840B.300d.txt'\n",
        "    emb_mean, emb_std = -0.005838499, 0.48782197\n",
        "\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_words, embed_size))\n",
        "    with open(EMBEDDING_FILE, 'r', encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            word, vec = line.split(' ', 1)\n",
        "            if word not in word_index:\n",
        "                continue\n",
        "            i = word_index[word]\n",
        "            if i >= max_words:\n",
        "                continue\n",
        "            embedding_vector = np.asarray(vec.split(' '), dtype='float32')[:300]\n",
        "            if len(embedding_vector) == 300:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqAHCcjRPdE9",
        "outputId": "305c8f63-bef4-4157-de2a-633178392152"
      },
      "source": [
        "Embedding_matrix = load_glove_fast(dict_glove,100000)\n",
        "Embedding_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.51004189,  0.48892707, -0.39317015, ..., -0.33855094,\n",
              "        -0.08941182, -1.10924053],\n",
              "       [-0.086864  ,  0.19160999,  0.10915   , ..., -0.01516   ,\n",
              "         0.11108   ,  0.20649999],\n",
              "       [ 0.27204001, -0.06203   , -0.1884    , ...,  0.13015001,\n",
              "        -0.18317001,  0.1323    ],\n",
              "       ...,\n",
              "       [-0.26304642, -0.34613858, -1.18406253, ...,  1.57106991,\n",
              "        -0.42640117, -0.28469739],\n",
              "       [-0.057969  , -0.14964999,  0.082356  , ..., -0.09207   ,\n",
              "         0.10385   ,  0.16963001],\n",
              "       [-0.067399  , -0.1991    , -0.11715   , ...,  0.36135   ,\n",
              "        -0.12372   ,  0.044732  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7xF9UcUJoqt",
        "outputId": "76fcebc8-3e7a-43d4-f21d-66289857f00d"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "# This is called to clear the original model session in order to use TensorBoard\n",
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "# Path to save model parameters\n",
        "\n",
        "\n",
        "int_sequences_input = keras.Input(shape=(70,), dtype=float)\n",
        "embedded_sequences = layers.Embedding(100000,300,weights=[Embedding_matrix],trainable=True,)(int_sequences_input)\n",
        "x = layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(64,return_sequences=True))(embedded_sequences)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "preds = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "new_model = keras.Model(int_sequences_input, preds)\n",
        "new_model.compile(optimizer=keras.optimizers.Adam(),loss='binary_crossentropy',metrics=['acc'])\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 70)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 70, 300)           30000000  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 70, 128)           187392    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 30,189,473\n",
            "Trainable params: 30,189,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4oAsC06KBs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9fce1f-ca51-4711-b19d-11213b202ab6"
      },
      "source": [
        "new_model.fit(X_train,Y_train, validation_data=(X_validation,Y_validation),\n",
        "          epochs=2, batch_size=512,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2169/2169 [==============================] - 658s 301ms/step - loss: 0.1337 - acc: 0.9486 - val_loss: 0.1007 - val_acc: 0.9593\n",
            "Epoch 2/2\n",
            "2169/2169 [==============================] - 659s 304ms/step - loss: 0.0921 - acc: 0.9633 - val_loss: 0.1002 - val_acc: 0.9601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa4901cdf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI2NYctvJC9c"
      },
      "source": [
        "y_predict_glove = new_model.predict(X_validation)\n",
        "y_predict1 = pd.DataFrame(y_predict_glove,columns=[\"Y_prediction_Proba\"])\n",
        "y_predict1[\"Y_prediction_final\"] = np.where(y_predict1.Y_prediction_Proba.values>=0.5,1,0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv63WWOZSCtN"
      },
      "source": [
        "y_predict1.to_csv(\"Glove_Prediction.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAr_oKJMwmvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6844ea0-f38e-43dd-a7d3-a617d4f5a1a9"
      },
      "source": [
        "f1score = f1_score(Y_validation,y_predict1.Y_prediction_final.values)\n",
        "print(\"F1_score of the model is \",f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_score of the model is  0.6685038368592869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzxipTtCelYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d46850-08b8-46cb-ebb7-562a1bda7c98"
      },
      "source": [
        "print(\"Find the best F1-score model\")\n",
        "for i in range(20,70,1):\n",
        "  y_predict = pd.DataFrame(y_predict_glove,columns=[\"Y_prediction\"])\n",
        "  y_predict[\"Y_prediction\"] = np.where(y_predict.Y_prediction.values>=(i/100),1,0)\n",
        "  f1score = f1_score(Y_validation,y_predict.Y_prediction.values)\n",
        "\n",
        "  print(\"F1 score of boundary = \"+str(i)+\"% is \"+str(f1score))\n",
        "  print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Find the best F1-score model\n",
            "F1 score of boundary = 20% is 0.6626349026028268\n",
            "\n",
            "F1 score of boundary = 21% is 0.6644385929376815\n",
            "\n",
            "F1 score of boundary = 22% is 0.6669851887243192\n",
            "\n",
            "F1 score of boundary = 23% is 0.6686879823594267\n",
            "\n",
            "F1 score of boundary = 24% is 0.6692409378696167\n",
            "\n",
            "F1 score of boundary = 25% is 0.6712093006919322\n",
            "\n",
            "F1 score of boundary = 26% is 0.6732974656661476\n",
            "\n",
            "F1 score of boundary = 27% is 0.6745182012847966\n",
            "\n",
            "F1 score of boundary = 28% is 0.6755171793488037\n",
            "\n",
            "F1 score of boundary = 29% is 0.6757295631683887\n",
            "\n",
            "F1 score of boundary = 30% is 0.6767296516940171\n",
            "\n",
            "F1 score of boundary = 31% is 0.6777875975843276\n",
            "\n",
            "F1 score of boundary = 32% is 0.6790953318230771\n",
            "\n",
            "F1 score of boundary = 33% is 0.6795317700736752\n",
            "\n",
            "F1 score of boundary = 34% is 0.679504088630968\n",
            "\n",
            "F1 score of boundary = 35% is 0.6795173408211278\n",
            "\n",
            "F1 score of boundary = 36% is 0.6796012679983195\n",
            "\n",
            "F1 score of boundary = 37% is 0.680184686417853\n",
            "\n",
            "F1 score of boundary = 38% is 0.6803116641469938\n",
            "\n",
            "F1 score of boundary = 39% is 0.6803294687121832\n",
            "\n",
            "F1 score of boundary = 40% is 0.6799323606905503\n",
            "\n",
            "F1 score of boundary = 41% is 0.6798099762470309\n",
            "\n",
            "F1 score of boundary = 42% is 0.6793896171162198\n",
            "\n",
            "F1 score of boundary = 43% is 0.6782490069413795\n",
            "\n",
            "F1 score of boundary = 44% is 0.6770163735597333\n",
            "\n",
            "F1 score of boundary = 45% is 0.6754664711154567\n",
            "\n",
            "F1 score of boundary = 46% is 0.6742735183056969\n",
            "\n",
            "F1 score of boundary = 47% is 0.6733074315946102\n",
            "\n",
            "F1 score of boundary = 48% is 0.6723900812669307\n",
            "\n",
            "F1 score of boundary = 49% is 0.6703352096110224\n",
            "\n",
            "F1 score of boundary = 50% is 0.6685038368592869\n",
            "\n",
            "F1 score of boundary = 51% is 0.6662107872467732\n",
            "\n",
            "F1 score of boundary = 52% is 0.6639941376783481\n",
            "\n",
            "F1 score of boundary = 53% is 0.6625473217005352\n",
            "\n",
            "F1 score of boundary = 54% is 0.6600245786516854\n",
            "\n",
            "F1 score of boundary = 55% is 0.657815542573907\n",
            "\n",
            "F1 score of boundary = 56% is 0.6549305214244225\n",
            "\n",
            "F1 score of boundary = 57% is 0.6521464646464646\n",
            "\n",
            "F1 score of boundary = 58% is 0.6492975037511935\n",
            "\n",
            "F1 score of boundary = 59% is 0.6454040658987655\n",
            "\n",
            "F1 score of boundary = 60% is 0.6419867488300978\n",
            "\n",
            "F1 score of boundary = 61% is 0.6371209284912018\n",
            "\n",
            "F1 score of boundary = 62% is 0.6318476154464244\n",
            "\n",
            "F1 score of boundary = 63% is 0.6264807030951471\n",
            "\n",
            "F1 score of boundary = 64% is 0.6220141871350674\n",
            "\n",
            "F1 score of boundary = 65% is 0.6162098897883547\n",
            "\n",
            "F1 score of boundary = 66% is 0.6086913628964632\n",
            "\n",
            "F1 score of boundary = 67% is 0.6019165502096228\n",
            "\n",
            "F1 score of boundary = 68% is 0.5940644117498358\n",
            "\n",
            "F1 score of boundary = 69% is 0.5838898592417548\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZuYYJhig2n-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bde65bd-9427-4ea4-ba5c-04528eb6835d"
      },
      "source": [
        "print(\"F1 score of boundary = 34% is 0.6755271465876758\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score of boundary = 34% is 0.6755271465876758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upVkiqvKuRAy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJi_SnX2qn5V"
      },
      "source": [
        "def load_fasttext_fast(word_index, max_words=100000, embed_size=300):\n",
        "    EMBEDDING_FILE = 'embedding/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
        "    emb_mean, emb_std = -0.0033470048, 0.109855264\n",
        "\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_words, embed_size))\n",
        "    with open(EMBEDDING_FILE, 'r', encoding=\"utf8\") as f:       \n",
        "        for line in f:\n",
        "            if len(line) <= 100:\n",
        "                continue\n",
        "            word, vec = line.split(' ', 1)\n",
        "            if word not in word_index:\n",
        "                continue\n",
        "            i = word_index[word]\n",
        "            if i >= max_words:\n",
        "                continue\n",
        "            embedding_vector = np.asarray(vec.split(' '), dtype='float32')[:300]\n",
        "            if len(embedding_vector) == 300:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB--AEnArMxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf852f4-200b-405d-e56a-5b9121d021e1"
      },
      "source": [
        "#use the same dictionary for fasttext\n",
        "embedding_matrix = load_fasttext_fast(dict_glove,100000)\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "\n",
        "int_sequences_input = keras.Input(shape=(70,), dtype=float)\n",
        "embedded_sequences = layers.Embedding(100000,300,weights=[Embedding_matrix],trainable=True,)(int_sequences_input)\n",
        "x = layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(64,return_sequences=True))(embedded_sequences)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "preds = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "new_model2 = keras.Model(int_sequences_input, preds)\n",
        "new_model2.compile(optimizer=keras.optimizers.Adam(),loss='binary_crossentropy',metrics=['acc'])\n",
        "new_model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 70)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 70, 300)           30000000  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 70, 128)           187392    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 30,189,473\n",
            "Trainable params: 30,189,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GZSD7-rrh1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e17310-b69a-465f-aee3-2c02de110a9a"
      },
      "source": [
        "new_model2.fit(X_train,Y_train, validation_data=(X_validation,Y_validation),\n",
        "          epochs=2, batch_size=512,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2169/2169 - 692s - loss: 0.1159 - acc: 0.9541 - val_loss: 0.1014 - val_acc: 0.9588\n",
            "Epoch 2/2\n",
            "2169/2169 - 694s - loss: 0.0927 - acc: 0.9629 - val_loss: 0.0994 - val_acc: 0.9603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa440053940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlsL2CByr41T"
      },
      "source": [
        "y_predict_fasttext = new_model2.predict(X_validation)\n",
        "y_predict = pd.DataFrame(y_predict_fasttext,columns=[\"Y_prediction\"])\n",
        "y_predict[\"Y_prediction_final\"] = np.where(y_predict.Y_prediction.values>=0.5,1,0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGdY6xr7vxE3",
        "outputId": "8a9030e2-1596-4337-e574-bdfdb1df3880"
      },
      "source": [
        "y_predict_fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.0429831e-02],\n",
              "       [3.9071412e-04],\n",
              "       [4.7073155e-04],\n",
              "       ...,\n",
              "       [1.6899848e-03],\n",
              "       [6.4358443e-05],\n",
              "       [1.7116500e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDmsGMRbsOep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1968466d-ce45-4fe8-ddb1-aea8212b8e49"
      },
      "source": [
        "f1score = f1_score(Y_validation,y_predict.Y_prediction_final.values)\n",
        "print(\"F1_score of the model is \",f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_score of the model is  0.6532470430707432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJxKe_gJsRVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0374c2b-a9f3-4576-caee-387b18af39b2"
      },
      "source": [
        "print(\"Find the best F1-score model\")\n",
        "for i in range(20,70,1):\n",
        "  y_predict = pd.DataFrame(y_predict_fasttext,columns=[\"Y_prediction\"])\n",
        "  y_predict[\"Y_prediction\"] = np.where(y_predict.Y_prediction.values>=(i/100),1,0)\n",
        "  f1score = f1_score(Y_validation,y_predict.Y_prediction.values)\n",
        "\n",
        "  print(\"F1 score of boundary = \"+str(i)+\"% is \"+str(f1score))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Find the best F1-score model\n",
            "F1 score of boundary = 20% is 0.6549534432270588\n",
            "\n",
            "F1 score of boundary = 21% is 0.6581595255547411\n",
            "\n",
            "F1 score of boundary = 22% is 0.661064425770308\n",
            "\n",
            "F1 score of boundary = 23% is 0.6635922661747626\n",
            "\n",
            "F1 score of boundary = 24% is 0.6654688687720267\n",
            "\n",
            "F1 score of boundary = 25% is 0.6681807064742672\n",
            "\n",
            "F1 score of boundary = 26% is 0.6694708564561167\n",
            "\n",
            "F1 score of boundary = 27% is 0.6706920575940548\n",
            "\n",
            "F1 score of boundary = 28% is 0.6723720795868992\n",
            "\n",
            "F1 score of boundary = 29% is 0.6737878235508568\n",
            "\n",
            "F1 score of boundary = 30% is 0.6747689021470925\n",
            "\n",
            "F1 score of boundary = 31% is 0.6752483351315153\n",
            "\n",
            "F1 score of boundary = 32% is 0.6752290821691452\n",
            "\n",
            "F1 score of boundary = 33% is 0.6765319673686208\n",
            "\n",
            "F1 score of boundary = 34% is 0.6765167464114833\n",
            "\n",
            "F1 score of boundary = 35% is 0.6769040343480447\n",
            "\n",
            "F1 score of boundary = 36% is 0.6781990706392284\n",
            "\n",
            "F1 score of boundary = 37% is 0.6772069550132083\n",
            "\n",
            "F1 score of boundary = 38% is 0.6760911118190507\n",
            "\n",
            "F1 score of boundary = 39% is 0.6755030726593565\n",
            "\n",
            "F1 score of boundary = 40% is 0.6737772730959526\n",
            "\n",
            "F1 score of boundary = 41% is 0.672015062830011\n",
            "\n",
            "F1 score of boundary = 42% is 0.6703887510339124\n",
            "\n",
            "F1 score of boundary = 43% is 0.6686422638674403\n",
            "\n",
            "F1 score of boundary = 44% is 0.6677911782069663\n",
            "\n",
            "F1 score of boundary = 45% is 0.6664678058550304\n",
            "\n",
            "F1 score of boundary = 46% is 0.664344984737091\n",
            "\n",
            "F1 score of boundary = 47% is 0.6618374251756745\n",
            "\n",
            "F1 score of boundary = 48% is 0.6587885154061625\n",
            "\n",
            "F1 score of boundary = 49% is 0.6556247515569099\n",
            "\n",
            "F1 score of boundary = 50% is 0.6532470430707432\n",
            "\n",
            "F1 score of boundary = 51% is 0.6499932405029066\n",
            "\n",
            "F1 score of boundary = 52% is 0.6474839765443884\n",
            "\n",
            "F1 score of boundary = 53% is 0.6434247393321391\n",
            "\n",
            "F1 score of boundary = 54% is 0.6404974016332591\n",
            "\n",
            "F1 score of boundary = 55% is 0.6352334037063102\n",
            "\n",
            "F1 score of boundary = 56% is 0.6306597057427622\n",
            "\n",
            "F1 score of boundary = 57% is 0.626080276550797\n",
            "\n",
            "F1 score of boundary = 58% is 0.6193021673632034\n",
            "\n",
            "F1 score of boundary = 59% is 0.6107778542629559\n",
            "\n",
            "F1 score of boundary = 60% is 0.6020916334661355\n",
            "\n",
            "F1 score of boundary = 61% is 0.5937137379546945\n",
            "\n",
            "F1 score of boundary = 62% is 0.5843730824299447\n",
            "\n",
            "F1 score of boundary = 63% is 0.5761568790205437\n",
            "\n",
            "F1 score of boundary = 64% is 0.5641349544712879\n",
            "\n",
            "F1 score of boundary = 65% is 0.5535924617196702\n",
            "\n",
            "F1 score of boundary = 66% is 0.543046357615894\n",
            "\n",
            "F1 score of boundary = 67% is 0.531151875723021\n",
            "\n",
            "F1 score of boundary = 68% is 0.5191232386490718\n",
            "\n",
            "F1 score of boundary = 69% is 0.5037491479209271\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5hHSSEa-B41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9b7c49-0488-4ed8-c318-116d1dfd965f"
      },
      "source": [
        "print(\"Best F1 score of Fasttext at boundary = 37% is \",0.6770760506486445)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best F1 score of Fasttext at boundary = 37% is  0.6770760506486445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L3GjIlZsvLS"
      },
      "source": [
        "Paragram_dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjMLSkyntL7t"
      },
      "source": [
        "def load_para_fast(word_index, max_words=100000, embed_size=300):\n",
        "    EMBEDDING_FILE = 'embedding/paragram_300_sl999/paragram_300_sl999.txt'\n",
        "    emb_mean, emb_std = -0.0053247833, 0.49346462\n",
        "\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_words, embed_size))\n",
        "    with open(EMBEDDING_FILE, 'r', encoding=\"utf8\", errors=\"ignore\") as f:        \n",
        "        for line in f:\n",
        "            if len(line) <= 100:\n",
        "                continue\n",
        "            word, vec = line.split(' ', 1)\n",
        "            if word not in word_index:\n",
        "                continue\n",
        "            i = word_index[word]\n",
        "            if i >= max_words:\n",
        "                continue\n",
        "            embedding_vector = np.asarray(vec.split(' '), dtype='float32')[:300]\n",
        "            if len(embedding_vector) == 300:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSH0LzLLstJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0254be38-dc4f-4cef-c7d7-42f51e6d00b8"
      },
      "source": [
        "paragram_dict = sort_dictionary(X,lower=True)\n",
        "paragram_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'?': 1381192,\n",
              " 'the': 665695,\n",
              " 'what': 471275,\n",
              " 'is': 471008,\n",
              " 'a': 411421,\n",
              " 'to': 407953,\n",
              " 'in': 378109,\n",
              " 'of': 333513,\n",
              " 'i': 331007,\n",
              " 'how': 290455,\n",
              " 'do': 269402,\n",
              " 'and': 257901,\n",
              " 'are': 249024,\n",
              " ',': 235096,\n",
              " 'for': 204464,\n",
              " 'you': 202227,\n",
              " 'can': 178103,\n",
              " 'why': 163946,\n",
              " 'it': 147606,\n",
              " '.': 134056,\n",
              " 'my': 112645,\n",
              " 'that': 107758,\n",
              " 'have': 99800,\n",
              " 'if': 98952,\n",
              " 'with': 95920,\n",
              " 'on': 94851,\n",
              " 'or': 94597,\n",
              " 'does': 92652,\n",
              " 'be': 92089,\n",
              " 'not': 86718,\n",
              " '\"': 73272,\n",
              " '#': 70598,\n",
              " 'from': 69848,\n",
              " 'your': 67682,\n",
              " 'an': 67354,\n",
              " '-': 67094,\n",
              " 'which': 65876,\n",
              " 'should': 65675,\n",
              " 'would': 63185,\n",
              " 'when': 62903,\n",
              " 'get': 62739,\n",
              " 'best': 62476,\n",
              " 'as': 60533,\n",
              " '(': 56618,\n",
              " ')': 56594,\n",
              " 'people': 55725,\n",
              " '##': 55397,\n",
              " 'some': 54458,\n",
              " 'there': 54408,\n",
              " 'will': 53308,\n",
              " 'who': 52259,\n",
              " 'like': 49484,\n",
              " 'at': 47937,\n",
              " 'about': 45165,\n",
              " 'did': 45103,\n",
              " 'they': 44459,\n",
              " 'by': 42706,\n",
              " 'was': 42365,\n",
              " '/': 42137,\n",
              " 'we': 40790,\n",
              " 'any': 40157,\n",
              " 'so': 39065,\n",
              " 'good': 38439,\n",
              " 'me': 36606,\n",
              " 'their': 34969,\n",
              " 'am': 33886,\n",
              " 'one': 33794,\n",
              " 'has': 32518,\n",
              " '####': 32499,\n",
              " 'india': 32140,\n",
              " 'after': 30724,\n",
              " 'most': 29294,\n",
              " 'where': 28647,\n",
              " 'make': 28296,\n",
              " 'this': 28127,\n",
              " 'but': 27919,\n",
              " 'more': 26759,\n",
              " 'all': 26404,\n",
              " 'think': 26066,\n",
              " 'many': 24526,\n",
              " 'between': 24345,\n",
              " 'time': 24104,\n",
              " 'than': 23950,\n",
              " 'much': 23481,\n",
              " 'other': 23092,\n",
              " 'he': 22988,\n",
              " 'life': 22513,\n",
              " 'someone': 21997,\n",
              " 'use': 21789,\n",
              " '’': 21317,\n",
              " 'out': 20981,\n",
              " 'way': 20880,\n",
              " 'know': 20166,\n",
              " '###': 19494,\n",
              " 'up': 19338,\n",
              " 'being': 19174,\n",
              " 'work': 18887,\n",
              " 'want': 18811,\n",
              " 'take': 18577,\n",
              " 'were': 18365,\n",
              " 'them': 18356,\n",
              " 'ever': 18005,\n",
              " 'his': 17772,\n",
              " 'us': 17671,\n",
              " 'find': 17429,\n",
              " 'could': 17054,\n",
              " 'become': 16995,\n",
              " 'world': 16787,\n",
              " 'without': 16690,\n",
              " 'just': 16676,\n",
              " 'person': 16277,\n",
              " 'feel': 16222,\n",
              " 'into': 16064,\n",
              " 'better': 16047,\n",
              " 'year': 16005,\n",
              " 'quora': 15752,\n",
              " 'no': 14988,\n",
              " 'go': 14919,\n",
              " 'new': 14516,\n",
              " 'possible': 14401,\n",
              " 's': 14302,\n",
              " 'job': 14243,\n",
              " 'only': 14164,\n",
              " 'her': 14092,\n",
              " 'years': 13871,\n",
              " 'been': 13859,\n",
              " 'indian': 13639,\n",
              " 'mean': 13613,\n",
              " 'used': 13202,\n",
              " 'need': 13191,\n",
              " 'start': 13173,\n",
              " 'trump': 13151,\n",
              " 'first': 12966,\n",
              " 'women': 12775,\n",
              " 'had': 12597,\n",
              " 'difference': 12449,\n",
              " 'money': 12411,\n",
              " 'still': 12237,\n",
              " 'different': 12073,\n",
              " 'school': 11778,\n",
              " 'really': 11750,\n",
              " 'while': 11750,\n",
              " 'long': 11748,\n",
              " 'old': 11610,\n",
              " 'country': 11514,\n",
              " 'over': 11508,\n",
              " 'our': 11417,\n",
              " 'learn': 11390,\n",
              " 'now': 11314,\n",
              " 'business': 11312,\n",
              " 'same': 11298,\n",
              " 'love': 11198,\n",
              " 'before': 11044,\n",
              " 'she': 11012,\n",
              " 'college': 10977,\n",
              " 'things': 10900,\n",
              " 'even': 10833,\n",
              " 'engineering': 10554,\n",
              " 'give': 10411,\n",
              " 'help': 10369,\n",
              " 'during': 10338,\n",
              " 'online': 10274,\n",
              " 'day': 10206,\n",
              " 'its': 10063,\n",
              " 'say': 10009,\n",
              " '+': 9839,\n",
              " 'see': 9701,\n",
              " 'bad': 9669,\n",
              " 'because': 9655,\n",
              " 'using': 9643,\n",
              " 'book': 9625,\n",
              " 'university': 9448,\n",
              " 'back': 9413,\n",
              " 'men': 9388,\n",
              " 'change': 9318,\n",
              " 'company': 9230,\n",
              " 'cannot': 9228,\n",
              " 'then': 9174,\n",
              " 'high': 9167,\n",
              " 'sex': 9156,\n",
              " 'him': 9072,\n",
              " 'made': 9032,\n",
              " 'stop': 9009,\n",
              " 'anyone': 8982,\n",
              " 'having': 8874,\n",
              " 'right': 8874,\n",
              " 'getting': 8862,\n",
              " 'girl': 8764,\n",
              " 'live': 8731,\n",
              " ':': 8688,\n",
              " 'student': 8678,\n",
              " 'buy': 8672,\n",
              " 'two': 8644,\n",
              " 'study': 8522,\n",
              " 'own': 8491,\n",
              " 'thing': 8480,\n",
              " 'happen': 8439,\n",
              " '&': 8413,\n",
              " 'science': 8285,\n",
              " 't': 8269,\n",
              " 'name': 8163,\n",
              " 'going': 8155,\n",
              " 'countries': 8087,\n",
              " 'white': 8070,\n",
              " 'something': 8001,\n",
              " 'free': 7884,\n",
              " 'through': 7880,\n",
              " 'real': 7821,\n",
              " 'english': 7741,\n",
              " 'look': 7714,\n",
              " 'black': 7639,\n",
              " 'china': 7603,\n",
              " 'american': 7578,\n",
              " 'true': 7567,\n",
              " 'experience': 7538,\n",
              " 'such': 7535,\n",
              " 'questions': 7489,\n",
              " 'come': 7488,\n",
              " 'doing': 7424,\n",
              " 'system': 7342,\n",
              " 'water': 7316,\n",
              " 'number': 7313,\n",
              " 'class': 7312,\n",
              " 'students': 7297,\n",
              " 'important': 7296,\n",
              " 'against': 7283,\n",
              " 'very': 7254,\n",
              " 'government': 7216,\n",
              " 'language': 7210,\n",
              " 'ways': 7140,\n",
              " 'state': 7078,\n",
              " 'books': 7062,\n",
              " 'man': 7052,\n",
              " 'off': 7049,\n",
              " 'tell': 7040,\n",
              " 'computer': 6990,\n",
              " 'war': 6941,\n",
              " 'keep': 6855,\n",
              " 'never': 6763,\n",
              " 'social': 6754,\n",
              " 'human': 6735,\n",
              " 'always': 6731,\n",
              " 'girls': 6717,\n",
              " 'every': 6685,\n",
              " 'friend': 6622,\n",
              " 'too': 6530,\n",
              " 'home': 6511,\n",
              " 'career': 6506,\n",
              " 'data': 6436,\n",
              " 'non': 6430,\n",
              " 'chinese': 6359,\n",
              " 'relationship': 6358,\n",
              " 'place': 6293,\n",
              " '%': 6233,\n",
              " 'x': 6217,\n",
              " 'under': 6206,\n",
              " 'software': 6177,\n",
              " 'write': 6171,\n",
              " 'friends': 6130,\n",
              " 'future': 6112,\n",
              " 'done': 6088,\n",
              " 'working': 6065,\n",
              " 'exam': 6013,\n",
              " 'learning': 5998,\n",
              " 'america': 5966,\n",
              " 'account': 5963,\n",
              " '##th': 5941,\n",
              " 'phone': 5934,\n",
              " 'app': 5907,\n",
              " 'website': 5904,\n",
              " 'family': 5882,\n",
              " 'food': 5869,\n",
              " 'parents': 5841,\n",
              " 'another': 5827,\n",
              " 'guy': 5826,\n",
              " 'top': 5822,\n",
              " 'got': 5772,\n",
              " 'age': 5729,\n",
              " 'car': 5716,\n",
              " 'around': 5716,\n",
              " 'believe': 5699,\n",
              " 'states': 5679,\n",
              " 'days': 5678,\n",
              " 'read': 5649,\n",
              " 'happens': 5636,\n",
              " 'course': 5627,\n",
              " 'usa': 5609,\n",
              " 'wrong': 5567,\n",
              " 'kind': 5560,\n",
              " 'big': 5559,\n",
              " 'google': 5533,\n",
              " 'each': 5500,\n",
              " 'companies': 5468,\n",
              " 'down': 5461,\n",
              " 'power': 5458,\n",
              " 'b': 5450,\n",
              " 'm': 5447,\n",
              " 'hard': 5439,\n",
              " 'show': 5430,\n",
              " 'body': 5417,\n",
              " 'able': 5416,\n",
              " 'major': 5395,\n",
              " 'americans': 5394,\n",
              " 'makes': 5392,\n",
              " 'also': 5378,\n",
              " 'movie': 5370,\n",
              " 'history': 5363,\n",
              " 'well': 5315,\n",
              " 'last': 5305,\n",
              " 'hate': 5287,\n",
              " 'question': 5272,\n",
              " 'ask': 5240,\n",
              " 'canada': 5216,\n",
              " 'muslims': 5214,\n",
              " 'cost': 5201,\n",
              " 'less': 5199,\n",
              " 'both': 5192,\n",
              " 'living': 5159,\n",
              " 'president': 5114,\n",
              " 'jee': 5113,\n",
              " 'considered': 5097,\n",
              " 'type': 5093,\n",
              " 'normal': 5092,\n",
              " 'pay': 5090,\n",
              " 'degree': 5082,\n",
              " 'create': 5075,\n",
              " 'woman': 5070,\n",
              " 'test': 5067,\n",
              " 'god': 5030,\n",
              " '^': 5018,\n",
              " 'since': 4979,\n",
              " 'part': 4975,\n",
              " 'facebook': 4952,\n",
              " 'instead': 4944,\n",
              " 'end': 4934,\n",
              " 'child': 4922,\n",
              " 'media': 4918,\n",
              " 'examples': 4887,\n",
              " 'play': 4880,\n",
              " 'great': 4876,\n",
              " 'u': 4872,\n",
              " 'common': 4860,\n",
              " 'children': 4851,\n",
              " 'answer': 4832,\n",
              " 'prepare': 4831,\n",
              " 'rank': 4827,\n",
              " 'favorite': 4825,\n",
              " 'process': 4810,\n",
              " 'market': 4808,\n",
              " 'actually': 4807,\n",
              " 'law': 4789,\n",
              " 'anything': 4757,\n",
              " 'united': 4734,\n",
              " 'given': 4721,\n",
              " 'house': 4720,\n",
              " 'eat': 4698,\n",
              " 'marks': 4682,\n",
              " 'win': 4677,\n",
              " 'myself': 4672,\n",
              " 'today': 4671,\n",
              " 'choose': 4667,\n",
              " 'earth': 4660,\n",
              " 'tv': 4652,\n",
              " 'medical': 4647,\n",
              " 'music': 4632,\n",
              " 'next': 4629,\n",
              " 'average': 4620,\n",
              " 'known': 4617,\n",
              " 'making': 4604,\n",
              " 'jobs': 4602,\n",
              " 'call': 4601,\n",
              " 'game': 4589,\n",
              " 'writing': 4554,\n",
              " 'cause': 4521,\n",
              " 'order': 4517,\n",
              " 'current': 4503,\n",
              " 'score': 4499,\n",
              " 'small': 4471,\n",
              " 'indians': 4454,\n",
              " 'e': 4444,\n",
              " 'video': 4434,\n",
              " 'north': 4432,\n",
              " 'join': 4423,\n",
              " 'affect': 4422,\n",
              " 'service': 4404,\n",
              " 'apply': 4398,\n",
              " 'deal': 4377,\n",
              " 'math': 4370,\n",
              " 'reason': 4368,\n",
              " 'main': 4334,\n",
              " 'self': 4331,\n",
              " 'causes': 4311,\n",
              " 'support': 4308,\n",
              " 'c': 4302,\n",
              " 'worth': 4274,\n",
              " 'left': 4267,\n",
              " '=': 4248,\n",
              " 'uk': 4244,\n",
              " '$': 4242,\n",
              " 'bank': 4228,\n",
              " 'these': 4226,\n",
              " 'called': 4220,\n",
              " 'form': 4213,\n",
              " 'south': 4172,\n",
              " 'tips': 4164,\n",
              " 'based': 4113,\n",
              " 'point': 4113,\n",
              " 'face': 4097,\n",
              " 'technology': 4095,\n",
              " 'word': 4089,\n",
              " 'etc': 4088,\n",
              " 'put': 4088,\n",
              " 'public': 4065,\n",
              " 'energy': 4061,\n",
              " 'open': 4057,\n",
              " 'delhi': 4052,\n",
              " 'engineer': 4052,\n",
              " 'muslim': 4051,\n",
              " 'months': 4023,\n",
              " 'card': 4021,\n",
              " 'travel': 4012,\n",
              " 'pakistan': 4007,\n",
              " 'iit': 3981,\n",
              " 'value': 3979,\n",
              " 'management': 3978,\n",
              " 'others': 3974,\n",
              " 'research': 3964,\n",
              " 'those': 3964,\n",
              " 'marketing': 3964,\n",
              " 'move': 3961,\n",
              " 'light': 3957,\n",
              " 'taking': 3957,\n",
              " 'level': 3954,\n",
              " 'full': 3950,\n",
              " 'hair': 3950,\n",
              " 'improve': 3945,\n",
              " 'development': 3940,\n",
              " 'design': 3937,\n",
              " 'lot': 3935,\n",
              " 'control': 3925,\n",
              " 'meaning': 3913,\n",
              " '”': 3911,\n",
              " 'date': 3891,\n",
              " 'problem': 3889,\n",
              " 'times': 3883,\n",
              " '“': 3871,\n",
              " 'found': 3855,\n",
              " 'idea': 3853,\n",
              " 'away': 3853,\n",
              " 'education': 3833,\n",
              " 'safe': 3833,\n",
              " 'term': 3827,\n",
              " 'single': 3827,\n",
              " 'program': 3822,\n",
              " 'health': 3817,\n",
              " 'air': 3802,\n",
              " 'care': 3794,\n",
              " 'city': 3793,\n",
              " 'physics': 3790,\n",
              " 'general': 3781,\n",
              " 'series': 3775,\n",
              " 'space': 3740,\n",
              " 'low': 3729,\n",
              " 'international': 3729,\n",
              " 'political': 3725,\n",
              " 'weight': 3724,\n",
              " 'enough': 3715,\n",
              " 'donald': 3709,\n",
              " 'required': 3707,\n",
              " 'stay': 3700,\n",
              " 'android': 3696,\n",
              " 'understand': 3694,\n",
              " 'field': 3687,\n",
              " 'talk': 3686,\n",
              " 'mba': 3676,\n",
              " 'increase': 3661,\n",
              " 'movies': 3658,\n",
              " 'month': 3637,\n",
              " 'youtube': 3614,\n",
              " 'popular': 3602,\n",
              " 'problems': 3594,\n",
              " 'programming': 3592,\n",
              " 'build': 3573,\n",
              " 'group': 3556,\n",
              " 'behind': 3554,\n",
              " 'humans': 3552,\n",
              " 'legal': 3550,\n",
              " 'salary': 3549,\n",
              " 'everyone': 3536,\n",
              " 'happened': 3535,\n",
              " 'available': 3528,\n",
              " 'post': 3511,\n",
              " '\\\\': 3495,\n",
              " 'death': 3488,\n",
              " 'mobile': 3483,\n",
              " 'often': 3474,\n",
              " 'again': 3473,\n",
              " 'said': 3471,\n",
              " 'military': 3467,\n",
              " 'mind': 3458,\n",
              " 'short': 3446,\n",
              " 'boyfriend': 3443,\n",
              " 'benefits': 3443,\n",
              " 'story': 3419,\n",
              " 'dog': 3415,\n",
              " 'female': 3410,\n",
              " 'civil': 3395,\n",
              " 'run': 3394,\n",
              " 'society': 3378,\n",
              " 'looking': 3371,\n",
              " 'girlfriend': 3359,\n",
              " 'kill': 3338,\n",
              " 'culture': 3326,\n",
              " 'wear': 3309,\n",
              " 'leave': 3307,\n",
              " 'successful': 3299,\n",
              " 'visa': 3269,\n",
              " 'russia': 3268,\n",
              " 'let': 3266,\n",
              " 'purpose': 3263,\n",
              " 'europe': 3259,\n",
              " 'ex': 3248,\n",
              " 'religion': 3248,\n",
              " 'due': 3240,\n",
              " 'mass': 3226,\n",
              " 'side': 3221,\n",
              " 'role': 3219,\n",
              " 'per': 3219,\n",
              " 'party': 3214,\n",
              " 'germany': 3212,\n",
              " 'web': 3209,\n",
              " 'related': 3207,\n",
              " 'kids': 3179,\n",
              " 'watch': 3174,\n",
              " 'information': 3172,\n",
              " 'admission': 3169,\n",
              " 'male': 3166,\n",
              " 'answers': 3161,\n",
              " 'die': 3157,\n",
              " 'past': 3154,\n",
              " 'consider': 3147,\n",
              " 'speed': 3142,\n",
              " 'british': 3136,\n",
              " 'skills': 3136,\n",
              " 'internet': 3134,\n",
              " 'try': 3134,\n",
              " 'tech': 3130,\n",
              " 'similar': 3128,\n",
              " 'force': 3121,\n",
              " 'starting': 3121,\n",
              " '{': 3121,\n",
              " 'colleges': 3116,\n",
              " 'mechanical': 3109,\n",
              " 'else': 3103,\n",
              " 'training': 3103,\n",
              " 'industry': 3101,\n",
              " 'guys': 3100,\n",
              " '}': 3099,\n",
              " 'product': 3092,\n",
              " 'everything': 3089,\n",
              " 'studying': 3083,\n",
              " 'few': 3080,\n",
              " 'gay': 3075,\n",
              " 'pain': 3071,\n",
              " 'seen': 3063,\n",
              " 'modern': 3053,\n",
              " 'opinion': 3051,\n",
              " 'lose': 3049,\n",
              " 'sell': 3049,\n",
              " 'yourself': 3041,\n",
              " 'cat': 3032,\n",
              " 'advice': 3031,\n",
              " 'types': 3030,\n",
              " 'share': 3026,\n",
              " 'site': 3024,\n",
              " 'fight': 3024,\n",
              " 'earn': 3014,\n",
              " 'games': 2998,\n",
              " 'tax': 2989,\n",
              " 'exist': 2982,\n",
              " 'effective': 2982,\n",
              " 'second': 2979,\n",
              " 'services': 2971,\n",
              " 'though': 2971,\n",
              " 'allowed': 2968,\n",
              " 'blood': 2956,\n",
              " 'personal': 2947,\n",
              " 'interview': 2947,\n",
              " 'application': 2946,\n",
              " 'night': 2946,\n",
              " 'rate': 2946,\n",
              " 'machine': 2940,\n",
              " 'korea': 2939,\n",
              " 'themselves': 2936,\n",
              " 'project': 2926,\n",
              " 'police': 2926,\n",
              " 'area': 2923,\n",
              " 'rather': 2913,\n",
              " 'australia': 2899,\n",
              " 'paper': 2898,\n",
              " 'code': 2898,\n",
              " 'foreign': 2896,\n",
              " 'famous': 2896,\n",
              " 'marriage': 2891,\n",
              " 'set': 2886,\n",
              " 'courses': 2886,\n",
              " 'bangalore': 2883,\n",
              " 'case': 2883,\n",
              " 'private': 2879,\n",
              " 'terms': 2878,\n",
              " 'period': 2865,\n",
              " ']': 2859,\n",
              " 'difficult': 2853,\n",
              " '[': 2853,\n",
              " 'already': 2851,\n",
              " 'effect': 2841,\n",
              " 'trying': 2837,\n",
              " 'easy': 2834,\n",
              " 'mumbai': 2834,\n",
              " 'color': 2822,\n",
              " 'brain': 2822,\n",
              " 'explain': 2811,\n",
              " 'compared': 2810,\n",
              " 'liberals': 2800,\n",
              " 'amount': 2793,\n",
              " 'act': 2792,\n",
              " 'daily': 2790,\n",
              " 'price': 2787,\n",
              " 'worst': 2776,\n",
              " 'plan': 2768,\n",
              " 'skin': 2767,\n",
              " 'middle': 2761,\n",
              " 'says': 2759,\n",
              " 'wants': 2754,\n",
              " 'treat': 2753,\n",
              " 'words': 2748,\n",
              " 'mother': 2745,\n",
              " 'neet': 2742,\n",
              " 'japanese': 2736,\n",
              " 'hours': 2736,\n",
              " 'team': 2735,\n",
              " 'towards': 2727,\n",
              " 'song': 2725,\n",
              " 'married': 2724,\n",
              " 'useful': 2721,\n",
              " 'universe': 2720,\n",
              " 'news': 2718,\n",
              " 'quality': 2710,\n",
              " 'places': 2709,\n",
              " 'function': 2707,\n",
              " 'biggest': 2704,\n",
              " 'follow': 2702,\n",
              " 'products': 2697,\n",
              " 'prevent': 2691,\n",
              " 'example': 2687,\n",
              " 'asked': 2682,\n",
              " 'correct': 2675,\n",
              " 'knowledge': 2671,\n",
              " 'sleep': 2669,\n",
              " 'once': 2667,\n",
              " 'seem': 2667,\n",
              " 'yet': 2663,\n",
              " 'visit': 2655,\n",
              " 'amazon': 2654,\n",
              " 'happy': 2650,\n",
              " 'turn': 2646,\n",
              " 'cse': 2636,\n",
              " 'ideas': 2636,\n",
              " 'young': 2635,\n",
              " 'rid': 2634,\n",
              " 'theory': 2634,\n",
              " 'national': 2630,\n",
              " 'institute': 2622,\n",
              " 'taken': 2618,\n",
              " 'three': 2617,\n",
              " 'started': 2614,\n",
              " 'wife': 2614,\n",
              " 'iphone': 2611,\n",
              " 'coaching': 2601,\n",
              " 'model': 2598,\n",
              " 'lost': 2594,\n",
              " 'describe': 2594,\n",
              " 'vs': 2592,\n",
              " 'offer': 2589,\n",
              " 'star': 2584,\n",
              " 'list': 2571,\n",
              " 'view': 2570,\n",
              " 'effects': 2570,\n",
              " 'invest': 2568,\n",
              " 'may': 2567,\n",
              " 'animals': 2567,\n",
              " 'oil': 2564,\n",
              " 'islam': 2562,\n",
              " 'gun': 2559,\n",
              " 'download': 2557,\n",
              " 'red': 2544,\n",
              " 'stock': 2537,\n",
              " 'line': 2519,\n",
              " 'differences': 2519,\n",
              " 'far': 2518,\n",
              " 'okay': 2518,\n",
              " 'avoid': 2516,\n",
              " 'week': 2504,\n",
              " 'matter': 2499,\n",
              " 'instagram': 2496,\n",
              " 'negative': 2487,\n",
              " '#####': 2485,\n",
              " 'fast': 2482,\n",
              " 'israel': 2480,\n",
              " 'character': 2471,\n",
              " 'thinking': 2462,\n",
              " 'little': 2456,\n",
              " 'expect': 2456,\n",
              " 'eating': 2456,\n",
              " 'com': 2449,\n",
              " 'natural': 2449,\n",
              " 'japan': 2447,\n",
              " 'security': 2445,\n",
              " 'sound': 2443,\n",
              " 'develop': 2441,\n",
              " 'chance': 2434,\n",
              " 'chemical': 2432,\n",
              " 'provide': 2430,\n",
              " 'jews': 2429,\n",
              " 'necessary': 2425,\n",
              " 'must': 2415,\n",
              " 'board': 2414,\n",
              " 'reasons': 2413,\n",
              " 'anti': 2408,\n",
              " 'don': 2408,\n",
              " 'exams': 2408,\n",
              " 'grow': 2404,\n",
              " 'sexual': 2404,\n",
              " 'modi': 2401,\n",
              " 'likely': 2400,\n",
              " 'present': 2395,\n",
              " 'size': 2394,\n",
              " 'professional': 2391,\n",
              " 'center': 2391,\n",
              " 'depression': 2388,\n",
              " 'remove': 2384,\n",
              " 'add': 2376,\n",
              " 'laptop': 2366,\n",
              " 'facts': 2365,\n",
              " 'chances': 2363,\n",
              " 'feeling': 2357,\n",
              " 'reading': 2356,\n",
              " 'large': 2355,\n",
              " 'accept': 2353,\n",
              " 'within': 2350,\n",
              " 'n': 2345,\n",
              " 'army': 2342,\n",
              " 'send': 2338,\n",
              " 'schools': 2337,\n",
              " 'dream': 2335,\n",
              " 'cut': 2334,\n",
              " 'apps': 2331,\n",
              " 'told': 2317,\n",
              " 'option': 2316,\n",
              " 'speak': 2313,\n",
              " 'together': 2310,\n",
              " 'prefer': 2301,\n",
              " 'office': 2298,\n",
              " 'moving': 2296,\n",
              " 'european': 2294,\n",
              " 'poor': 2285,\n",
              " 'preparation': 2280,\n",
              " '!': 2276,\n",
              " 'interested': 2276,\n",
              " 'becoming': 2275,\n",
              " 'father': 2275,\n",
              " 'investment': 2274,\n",
              " 'fake': 2267,\n",
              " 'fall': 2262,\n",
              " 'least': 2260,\n",
              " 'head': 2259,\n",
              " 'phd': 2259,\n",
              " 'graduate': 2258,\n",
              " 'boy': 2254,\n",
              " 'financial': 2253,\n",
              " 'digital': 2251,\n",
              " 'close': 2248,\n",
              " 'break': 2248,\n",
              " 'interesting': 2241,\n",
              " 'paid': 2234,\n",
              " 'income': 2232,\n",
              " 'nothing': 2232,\n",
              " 'mental': 2226,\n",
              " 'western': 2225,\n",
              " 'here': 2221,\n",
              " 'thoughts': 2220,\n",
              " 'dating': 2213,\n",
              " 'illegal': 2212,\n",
              " 'options': 2210,\n",
              " 'impact': 2207,\n",
              " 'percentage': 2207,\n",
              " 'outside': 2202,\n",
              " 'nuclear': 2202,\n",
              " 'contact': 2198,\n",
              " 'drive': 2197,\n",
              " 'basic': 2191,\n",
              " 'subject': 2191,\n",
              " 'french': 2183,\n",
              " 'husband': 2178,\n",
              " 'upsc': 2178,\n",
              " 'universities': 2172,\n",
              " 'gain': 2156,\n",
              " 'allow': 2154,\n",
              " 'comes': 2154,\n",
              " 'store': 2152,\n",
              " 'studies': 2152,\n",
              " 'higher': 2149,\n",
              " 'uses': 2149,\n",
              " 'languages': 2143,\n",
              " 'land': 2142,\n",
              " 'population': 2137,\n",
              " 'java': 2136,\n",
              " 'd': 2135,\n",
              " 'style': 2130,\n",
              " 'physical': 2129,\n",
              " 'might': 2125,\n",
              " 'born': 2123,\n",
              " 'interest': 2122,\n",
              " 'rights': 2121,\n",
              " 'hand': 2120,\n",
              " 'special': 2114,\n",
              " 'chemistry': 2111,\n",
              " 'gate': 2111,\n",
              " 'mains': 2108,\n",
              " 'solution': 2107,\n",
              " 'advantages': 2106,\n",
              " 'characteristics': 2103,\n",
              " 'check': 2097,\n",
              " 'personality': 2097,\n",
              " 'german': 2091,\n",
              " 'websites': 2090,\n",
              " 'changed': 2085,\n",
              " 'racist': 2085,\n",
              " 'issues': 2084,\n",
              " 'baby': 2080,\n",
              " 'intelligence': 2079,\n",
              " 'email': 2078,\n",
              " 'teacher': 2075,\n",
              " 'please': 2075,\n",
              " 'fact': 2074,\n",
              " 'gets': 2072,\n",
              " 'heart': 2068,\n",
              " 'developer': 2066,\n",
              " 'rich': 2062,\n",
              " 'created': 2054,\n",
              " 'recommend': 2054,\n",
              " 'meet': 2052,\n",
              " 'branch': 2051,\n",
              " 'strong': 2049,\n",
              " 'fat': 2047,\n",
              " 'pressure': 2047,\n",
              " 'room': 2046,\n",
              " 'russian': 2044,\n",
              " 'credit': 2042,\n",
              " 'west': 2038,\n",
              " 'pregnant': 2035,\n",
              " 'obama': 2034,\n",
              " 'sites': 2033,\n",
              " 'economy': 2029,\n",
              " 'ms': 2028,\n",
              " 'marry': 2027,\n",
              " 'hindi': 2025,\n",
              " 'dark': 2017,\n",
              " 'doctor': 2015,\n",
              " 'startup': 2014,\n",
              " 'currently': 2013,\n",
              " 'positive': 2011,\n",
              " 'pass': 2010,\n",
              " 'charge': 2009,\n",
              " 'structure': 2008,\n",
              " 'laws': 2007,\n",
              " 'source': 2003,\n",
              " 'pursue': 2000,\n",
              " 'near': 1999,\n",
              " 'inside': 1998,\n",
              " 'practice': 1995,\n",
              " 'son': 1995,\n",
              " 'solve': 1994,\n",
              " 'early': 1993,\n",
              " 'hyderabad': 1991,\n",
              " 'scope': 1990,\n",
              " 'spend': 1989,\n",
              " 'apple': 1982,\n",
              " 'talking': 1981,\n",
              " 'smart': 1980,\n",
              " '#th': 1976,\n",
              " 'building': 1976,\n",
              " 'bring': 1973,\n",
              " 'ok': 1966,\n",
              " 'bitcoin': 1965,\n",
              " 'africa': 1964,\n",
              " 'whole': 1964,\n",
              " 'crush': 1963,\n",
              " 'views': 1961,\n",
              " 'christians': 1959,\n",
              " 'network': 1959,\n",
              " 'completely': 1955,\n",
              " 'videos': 1952,\n",
              " 'windows': 1951,\n",
              " 'numbers': 1951,\n",
              " 'maths': 1950,\n",
              " 'art': 1950,\n",
              " 'partner': 1945,\n",
              " '…': 1928,\n",
              " 'topics': 1928,\n",
              " 'ca': 1928,\n",
              " 'alone': 1927,\n",
              " 'officer': 1926,\n",
              " 'ones': 1924,\n",
              " 'certain': 1921,\n",
              " 'among': 1920,\n",
              " 'especially': 1918,\n",
              " 'healthy': 1918,\n",
              " 'pune': 1917,\n",
              " 'global': 1916,\n",
              " 'film': 1912,\n",
              " 'content': 1911,\n",
              " 'cell': 1911,\n",
              " 'gas': 1910,\n",
              " 'iq': 1909,\n",
              " 'cbse': 1908,\n",
              " 'works': 1908,\n",
              " 'text': 1906,\n",
              " 'factors': 1906,\n",
              " 'written': 1905,\n",
              " 'exactly': 1904,\n",
              " 'complete': 1903,\n",
              " 'according': 1903,\n",
              " 'christian': 1902,\n",
              " 'needed': 1900,\n",
              " 'dogs': 1895,\n",
              " 'fear': 1894,\n",
              " 'distance': 1892,\n",
              " 'stupid': 1892,\n",
              " 'asian': 1890,\n",
              " 'save': 1889,\n",
              " 'mom': 1889,\n",
              " 'religious': 1886,\n",
              " 'yes': 1885,\n",
              " 'reduce': 1883,\n",
              " 'cold': 1881,\n",
              " 'songs': 1877,\n",
              " 'ago': 1875,\n",
              " 'treatment': 1874,\n",
              " 'east': 1856,\n",
              " 'electrical': 1854,\n",
              " 'file': 1852,\n",
              " 'coming': 1850,\n",
              " 'playing': 1849,\n",
              " 'hurt': 1848,\n",
              " 'insurance': 1845,\n",
              " 'eyes': 1844,\n",
              " 'cs': 1841,\n",
              " 'giving': 1841,\n",
              " 'race': 1840,\n",
              " 'attack': 1839,\n",
              " 'buying': 1838,\n",
              " 'teach': 1838,\n",
              " 'minimum': 1836,\n",
              " 'advanced': 1833,\n",
              " 'policy': 1831,\n",
              " 'african': 1831,\n",
              " 'train': 1830,\n",
              " 'simple': 1830,\n",
              " 'novel': 1829,\n",
              " 'community': 1828,\n",
              " 'letter': 1827,\n",
              " 'opportunities': 1823,\n",
              " 'fix': 1814,\n",
              " 'democrats': 1814,\n",
              " 'dead': 1813,\n",
              " 'multiple': 1806,\n",
              " 'thought': 1803,\n",
              " 'running': 1794,\n",
              " 'sense': 1791,\n",
              " 'react': 1787,\n",
              " 'abroad': 1787,\n",
              " 'mathematics': 1787,\n",
              " 'method': 1786,\n",
              " 'result': 1785,\n",
              " 'almost': 1783,\n",
              " 'procedure': 1782,\n",
              " 'easily': 1780,\n",
              " 'eye': 1775,\n",
              " 'lead': 1774,\n",
              " 'anxiety': 1772,\n",
              " 'transfer': 1770,\n",
              " 'front': 1769,\n",
              " 'hindu': 1767,\n",
              " 'clear': 1764,\n",
              " 'football': 1763,\n",
              " 'lower': 1763,\n",
              " 'g': 1762,\n",
              " 'half': 1761,\n",
              " 'green': 1759,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wokypE38stL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b170d9-c807-4c35-ac72-b1cb2e753ea0"
      },
      "source": [
        "embedding_layer = load_para_fast(paragram_dict,100000)\n",
        "\n",
        "\n",
        "int_sequences_input = keras.Input(shape=(70,), dtype=float)\n",
        "embedded_sequences = layers.Embedding(100000,300,weights=[Embedding_matrix],trainable=True,)(int_sequences_input)\n",
        "x = layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(64,return_sequences=True))(embedded_sequences)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "preds = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "new_model3 = keras.Model(int_sequences_input, preds)\n",
        "new_model3.compile(optimizer=keras.optimizers.Adam(),loss='binary_crossentropy',metrics=['acc'])\n",
        "new_model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 70)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 70, 300)           30000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 70, 128)           187392    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 30,189,473\n",
            "Trainable params: 30,189,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h67FC_oostOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b18e7e-5f45-43da-e9ce-0c1b3a2d8f93"
      },
      "source": [
        "new_model3.fit(X_train,Y_train, validation_data=(X_validation,Y_validation),\n",
        "          epochs=2, batch_size=512,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2169/2169 - 665s - loss: 0.1150 - acc: 0.9555 - val_loss: 0.1026 - val_acc: 0.9594\n",
            "Epoch 2/2\n",
            "2169/2169 - 658s - loss: 0.0925 - acc: 0.9631 - val_loss: 0.1002 - val_acc: 0.9601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa42a5a1860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P04zVzwMstQX"
      },
      "source": [
        "y_predict_paragram = new_model3.predict(X_validation)\n",
        "y_predict = pd.DataFrame(y_predict_paragram,columns=[\"Y_prediction\"])\n",
        "y_predict[\"Y_prediction_final\"] = np.where(y_predict.Y_prediction.values>=0.5,1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86TgNekw2K0S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "16300f98-1299-4559-ecc4-8249d54aedd3"
      },
      "source": [
        "y_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_prediction</th>\n",
              "      <th>Y_prediction_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.062933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000192</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000356</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.230677</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000074</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195914</th>\n",
              "      <td>0.001801</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195915</th>\n",
              "      <td>0.005098</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195916</th>\n",
              "      <td>0.000912</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195917</th>\n",
              "      <td>0.000051</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195918</th>\n",
              "      <td>0.000043</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>195919 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Y_prediction  Y_prediction_final\n",
              "0           0.062933                   0\n",
              "1           0.000192                   0\n",
              "2           0.000356                   0\n",
              "3           0.230677                   0\n",
              "4           0.000074                   0\n",
              "...              ...                 ...\n",
              "195914      0.001801                   0\n",
              "195915      0.005098                   0\n",
              "195916      0.000912                   0\n",
              "195917      0.000051                   0\n",
              "195918      0.000043                   0\n",
              "\n",
              "[195919 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRv4GcQostS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6351c5a-fc00-4b76-afd2-767f811d8dd5"
      },
      "source": [
        "f1score = f1_score(Y_validation,y_predict.Y_prediction_final.values)\n",
        "print(\"F1_score of the model is \",f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_score of the model is  0.6591930207197382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ah8x6MbsWOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd48e24-b708-42cc-feca-3aaf856e618b"
      },
      "source": [
        "print(\"Find the best F1-score model\")\n",
        "for i in range(20,70,1):\n",
        "  y_predict = pd.DataFrame(y_predict_paragram,columns=[\"Y_prediction\"])\n",
        "  y_predict[\"Y_prediction\"] = np.where(y_predict.Y_prediction.values>=(i/100),1,0)\n",
        "  f1score = f1_score(Y_validation,y_predict.Y_prediction.values)\n",
        "\n",
        "  print(\"F1 score of boundary = \"+str(i)+\"% is\"+str(f1score))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Find the best F1-score model\n",
            "F1 score of boundary = 20% is0.664916646780077\n",
            "\n",
            "F1 score of boundary = 21% is0.6671032676134013\n",
            "\n",
            "F1 score of boundary = 22% is0.6677355268202573\n",
            "\n",
            "F1 score of boundary = 23% is0.6697923643670463\n",
            "\n",
            "F1 score of boundary = 24% is0.6714402764418795\n",
            "\n",
            "F1 score of boundary = 25% is0.6729476068898559\n",
            "\n",
            "F1 score of boundary = 26% is0.6746716970180657\n",
            "\n",
            "F1 score of boundary = 27% is0.6760099531615925\n",
            "\n",
            "F1 score of boundary = 28% is0.6772147230213175\n",
            "\n",
            "F1 score of boundary = 29% is0.6780518659076533\n",
            "\n",
            "F1 score of boundary = 30% is0.6790600052471797\n",
            "\n",
            "F1 score of boundary = 31% is0.6796644751756972\n",
            "\n",
            "F1 score of boundary = 32% is0.6797699310554983\n",
            "\n",
            "F1 score of boundary = 33% is0.679745085995086\n",
            "\n",
            "F1 score of boundary = 34% is0.679368029739777\n",
            "\n",
            "F1 score of boundary = 35% is0.6789699570815451\n",
            "\n",
            "F1 score of boundary = 36% is0.6792986870036953\n",
            "\n",
            "F1 score of boundary = 37% is0.6781204227861131\n",
            "\n",
            "F1 score of boundary = 38% is0.676268751994893\n",
            "\n",
            "F1 score of boundary = 39% is0.6750583125552965\n",
            "\n",
            "F1 score of boundary = 40% is0.6745260087506076\n",
            "\n",
            "F1 score of boundary = 41% is0.6739866933344218\n",
            "\n",
            "F1 score of boundary = 42% is0.6725889368702447\n",
            "\n",
            "F1 score of boundary = 43% is0.6717734255310338\n",
            "\n",
            "F1 score of boundary = 44% is0.6707515318244341\n",
            "\n",
            "F1 score of boundary = 45% is0.6695495192913221\n",
            "\n",
            "F1 score of boundary = 46% is0.6673149283388999\n",
            "\n",
            "F1 score of boundary = 47% is0.6652479250904448\n",
            "\n",
            "F1 score of boundary = 48% is0.6640360283079564\n",
            "\n",
            "F1 score of boundary = 49% is0.6620844680759088\n",
            "\n",
            "F1 score of boundary = 50% is0.6591930207197382\n",
            "\n",
            "F1 score of boundary = 51% is0.6557564559412257\n",
            "\n",
            "F1 score of boundary = 52% is0.6533002129169624\n",
            "\n",
            "F1 score of boundary = 53% is0.6513708126481506\n",
            "\n",
            "F1 score of boundary = 54% is0.6487241907853214\n",
            "\n",
            "F1 score of boundary = 55% is0.6454255803368228\n",
            "\n",
            "F1 score of boundary = 56% is0.64227007667937\n",
            "\n",
            "F1 score of boundary = 57% is0.6391743034342313\n",
            "\n",
            "F1 score of boundary = 58% is0.6346584546472565\n",
            "\n",
            "F1 score of boundary = 59% is0.6304276083164396\n",
            "\n",
            "F1 score of boundary = 60% is0.6264097073518915\n",
            "\n",
            "F1 score of boundary = 61% is0.6223118279569891\n",
            "\n",
            "F1 score of boundary = 62% is0.6163405990582067\n",
            "\n",
            "F1 score of boundary = 63% is0.6111846297113169\n",
            "\n",
            "F1 score of boundary = 64% is0.6065703542450029\n",
            "\n",
            "F1 score of boundary = 65% is0.5986980470706059\n",
            "\n",
            "F1 score of boundary = 66% is0.5902070990936249\n",
            "\n",
            "F1 score of boundary = 67% is0.5819764464925755\n",
            "\n",
            "F1 score of boundary = 68% is0.575528387898881\n",
            "\n",
            "F1 score of boundary = 69% is0.5658198614318707\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF4rp-ib0UoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b79762ba-f493-499f-bd24-38e362ec50a1"
      },
      "source": [
        "print(\"Best F1 score at boundary = 28% is\",0.6730135210224115)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best F1 score at boundary = 28% is 0.6730135210224115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esy5_pyW-tfk"
      },
      "source": [
        "Use three word_embedding_layer at the same_time & Basic Boosting algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuXGOEyo2u3k"
      },
      "source": [
        "coefficient = [0.33,0.33,0.34] #for glove fasttext and paragram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmc8SYSCGSry"
      },
      "source": [
        "basic_ensemble = 0.33*y_predict_glove+0.33*y_predict_fasttext+0.34*y_predict_paragram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuYouQLX3Pzo"
      },
      "source": [
        "ensemble_df = pd.DataFrame(basic_ensemble,columns=[\"Y_prediction_Proba\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-J6F6Yt3XpT",
        "outputId": "b30de3e8-9a7d-4582-e17b-1d4a1aad244e"
      },
      "source": [
        "print(\"Find the best F1-score model\")\n",
        "for i in range(20,70,1):\n",
        "  ensemble_df[\"Y_prediction\"] = np.where(ensemble_df.Y_prediction_Proba.values >=(i/100),1,0)\n",
        "  f1score = f1_score(Y_validation,ensemble_df.Y_prediction.values)\n",
        "  print(\"F1 score of boundary = \"+str(i)+\"% is \"+str(f1score))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Find the best F1-score model\n",
            "F1 score of boundary = 20% is 0.6665555518517283\n",
            "\n",
            "F1 score of boundary = 21% is 0.6689366866698131\n",
            "\n",
            "F1 score of boundary = 22% is 0.6714865463970263\n",
            "\n",
            "F1 score of boundary = 23% is 0.6731538992408558\n",
            "\n",
            "F1 score of boundary = 24% is 0.675384454440841\n",
            "\n",
            "F1 score of boundary = 25% is 0.6775115565122269\n",
            "\n",
            "F1 score of boundary = 26% is 0.6785447029897017\n",
            "\n",
            "F1 score of boundary = 27% is 0.6790416576732139\n",
            "\n",
            "F1 score of boundary = 28% is 0.6809515162520429\n",
            "\n",
            "F1 score of boundary = 29% is 0.6818548091714893\n",
            "\n",
            "F1 score of boundary = 30% is 0.6822015090989793\n",
            "\n",
            "F1 score of boundary = 31% is 0.6838863797543951\n",
            "\n",
            "F1 score of boundary = 32% is 0.6850047036688617\n",
            "\n",
            "F1 score of boundary = 33% is 0.6842624943035089\n",
            "\n",
            "F1 score of boundary = 34% is 0.6849398974044866\n",
            "\n",
            "F1 score of boundary = 35% is 0.6852731132985911\n",
            "\n",
            "F1 score of boundary = 36% is 0.68545405005644\n",
            "\n",
            "F1 score of boundary = 37% is 0.685420590081607\n",
            "\n",
            "F1 score of boundary = 38% is 0.6857866213062225\n",
            "\n",
            "F1 score of boundary = 39% is 0.6854497565647697\n",
            "\n",
            "F1 score of boundary = 40% is 0.6839057347381967\n",
            "\n",
            "F1 score of boundary = 41% is 0.6830454877158842\n",
            "\n",
            "F1 score of boundary = 42% is 0.6811677160847167\n",
            "\n",
            "F1 score of boundary = 43% is 0.6792686450121755\n",
            "\n",
            "F1 score of boundary = 44% is 0.6786576734116079\n",
            "\n",
            "F1 score of boundary = 45% is 0.6771091420652584\n",
            "\n",
            "F1 score of boundary = 46% is 0.6745782826142239\n",
            "\n",
            "F1 score of boundary = 47% is 0.6724469311920728\n",
            "\n",
            "F1 score of boundary = 48% is 0.6702572277995605\n",
            "\n",
            "F1 score of boundary = 49% is 0.6684041351750499\n",
            "\n",
            "F1 score of boundary = 50% is 0.6664912511511644\n",
            "\n",
            "F1 score of boundary = 51% is 0.6642762284196547\n",
            "\n",
            "F1 score of boundary = 52% is 0.6613076098606646\n",
            "\n",
            "F1 score of boundary = 53% is 0.657797420402273\n",
            "\n",
            "F1 score of boundary = 54% is 0.6540932075987426\n",
            "\n",
            "F1 score of boundary = 55% is 0.6514022988505748\n",
            "\n",
            "F1 score of boundary = 56% is 0.6473918693150176\n",
            "\n",
            "F1 score of boundary = 57% is 0.6415572232645403\n",
            "\n",
            "F1 score of boundary = 58% is 0.6371731716559302\n",
            "\n",
            "F1 score of boundary = 59% is 0.6310651737008326\n",
            "\n",
            "F1 score of boundary = 60% is 0.6251993620414673\n",
            "\n",
            "F1 score of boundary = 61% is 0.6211847438589637\n",
            "\n",
            "F1 score of boundary = 62% is 0.6147237446304251\n",
            "\n",
            "F1 score of boundary = 63% is 0.6064303215160758\n",
            "\n",
            "F1 score of boundary = 64% is 0.5979767324228629\n",
            "\n",
            "F1 score of boundary = 65% is 0.5893680221243469\n",
            "\n",
            "F1 score of boundary = 66% is 0.5810067462376751\n",
            "\n",
            "F1 score of boundary = 67% is 0.5709925271024102\n",
            "\n",
            "F1 score of boundary = 68% is 0.5593419506462984\n",
            "\n",
            "F1 score of boundary = 69% is 0.5470817964851378\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03YogAQP3qap",
        "outputId": "ac6196b9-2320-4058-d9ea-55203d0a4d62"
      },
      "source": [
        "print(\"F1 score of boundary = 38% is 0.6857866213062225\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score of boundary = 38% is 0.6857866213062225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsfsiM1i56LR"
      },
      "source": [
        "def find_best_score(dataframe):\n",
        "  list1 = []\n",
        "  for i in range(30,50,1):\n",
        "    dataframe[\"Y_prediction\"] = np.where(dataframe.Y_prediction_Proba.values >=(i/100),1,0)\n",
        "    f1score = f1_score(Y_validation,dataframe.Y_prediction.values)\n",
        "    list1.append([i,f1score])\n",
        "  list_a = sorted(list1,key = lambda x:x[1],reverse=True)\n",
        "  return list_a[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeHEs--d7hOK",
        "outputId": "8bb5d2e0-cebb-4796-bdb3-7e6372fce6c5"
      },
      "source": [
        "find_best_score(ensemble_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[38, 0.6857866213062225]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSgucqom4DdV"
      },
      "source": [
        "list_a = []\n",
        "for i in np.arange(0.20,0.50,0.01):\n",
        "  for j in np.arange(0.20,0.50,0.01):\n",
        "    for k in np.arange(0.20,0.50,0.01):\n",
        "      i = round(i,2)\n",
        "      j = round(j,2)\n",
        "      k = round(k,2)\n",
        "      if i+j+k ==1:\n",
        "        basic_ensemble2 = i*y_predict_glove + j*y_predict_fasttext + k*y_predict_paragram\n",
        "        ensemble_df2 = pd.DataFrame(basic_ensemble2,columns=[\"Y_prediction_Proba\"])\n",
        "        best_f1score_for_coefficient = find_best_score(ensemble_df2)\n",
        "        f1_best_score_coefficient = best_f1score_for_coefficient[1]\n",
        "        best_boundary_for_coefficient = best_f1score_for_coefficient[0]\n",
        "        coefficient = [i,j,k] #glove fasttext paragram\n",
        "        list_a.append([coefficient,best_boundary_for_coefficient,f1_best_score_coefficient])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUr_NHTD9lyz"
      },
      "source": [
        "sort_list_a = sorted(list_a,key=lambda x:x[2],reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7fpxZda5Lmt",
        "outputId": "6a30db8c-0cef-40eb-9759-b08742b5606e"
      },
      "source": [
        "best_parameter = sort_list_a[0][0]\n",
        "best_parameter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38, 0.21, 0.41]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPuZTXI1FnUm",
        "outputId": "a1549aff-77fe-418f-96b1-f8379a1ced2f"
      },
      "source": [
        "list_ab = sort_list_a[0]\n",
        "list_ab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.38, 0.21, 0.41], 35, 0.6864818960858489]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJcJIdyE-f6L",
        "outputId": "d02751e2-6467-4de0-dd12-cefa1d70514e"
      },
      "source": [
        "len(list_a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "655"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igAgETtBBIfd"
      },
      "source": [
        "parameter_tuning_Answer = best_parameter[0]*y_predict_glove + best_parameter[1]*y_predict_fasttext + best_parameter[2]*y_predict_paragram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Du7kVms-x-D",
        "outputId": "252ceb04-bd98-471d-9770-7917c68d5a09"
      },
      "source": [
        "parameter_tuning_Answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.8212405e-02],\n",
              "       [2.9087716e-04],\n",
              "       [3.8961406e-04],\n",
              "       ...,\n",
              "       [1.5532168e-03],\n",
              "       [7.0507696e-05],\n",
              "       [7.8445752e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AOPwz19GEyG"
      },
      "source": [
        "ensemble_df_best_tuning = pd.DataFrame(parameter_tuning_Answer,columns=[\"Y_prediction_Proba\"])\n",
        "ensemble_df_best_tuning[\"Y_prediction\"] = np.where(ensemble_df_best_tuning.Y_prediction_Proba>=0.34,1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "5g2WWgmkGIK2",
        "outputId": "c1af41e9-f162-46df-9bc7-3f048c154b9c"
      },
      "source": [
        "ensemble_df_best_tuning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_prediction_Proba</th>\n",
              "      <th>Y_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.068212</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000291</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000390</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.194979</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000069</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195914</th>\n",
              "      <td>0.001597</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195915</th>\n",
              "      <td>0.005696</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195916</th>\n",
              "      <td>0.001553</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195917</th>\n",
              "      <td>0.000071</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195918</th>\n",
              "      <td>0.000078</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>195919 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Y_prediction_Proba  Y_prediction\n",
              "0                 0.068212             0\n",
              "1                 0.000291             0\n",
              "2                 0.000390             0\n",
              "3                 0.194979             0\n",
              "4                 0.000069             0\n",
              "...                    ...           ...\n",
              "195914            0.001597             0\n",
              "195915            0.005696             0\n",
              "195916            0.001553             0\n",
              "195917            0.000071             0\n",
              "195918            0.000078             0\n",
              "\n",
              "[195919 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV3tVqy3Gol_",
        "outputId": "cd271521-432f-4534-ab1b-d9cd21962152"
      },
      "source": [
        "print(\"Best Coefficient of Glove = \",list_ab[0][0])\n",
        "print(\"Best Coefficient of Fasttext = \",list_ab[0][1])\n",
        "print(\"Best Coefficient of Paragram = \",list_ab[0][2])\n",
        "print(\"Boundary = \",list_ab[1])\n",
        "print(\"Best F1 score = \",find_best_score(ensemble_df_best_tuning)[1])\n",
        "print(\"Boundary found to check again\",find_best_score(ensemble_df_best_tuning)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Coefficient of Glove =  0.38\n",
            "Best Coefficient of Fasttext =  0.21\n",
            "Best Coefficient of Paragram =  0.41\n",
            "Boundary =  35\n",
            "Best F1 score =  0.6864818960858489\n",
            "Boundary found to check again 35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA_LG0L7G1x7"
      },
      "source": [
        "clean_test = test.copy()\n",
        "clean_test[\"question_text\"]= clean_test.question_text.apply(lambda x: clean_text(x))\n",
        "clean_test[\"question_text\"]= clean_test.question_text.apply(lambda x: clean_numbers(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbXAjA2Lt82k"
      },
      "source": [
        "clean_test[\"question_text\"] = clean_test[\"question_text\"].apply(lambda x: check_missspell(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xiZcSUWt85I"
      },
      "source": [
        "Test_X = clean_test.question_text.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGphkgSw_ym7",
        "outputId": "ef7fa2d1-6b67-44f3-9e1f-bbfb99240526"
      },
      "source": [
        "Test_X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Why do so many women become so rude and arrogant when they get just a little bit of wealth and power ? ',\n",
              "       'When should I apply for RV college of engineering and BMS college of engineering ?  Should I wait for the COMEDK result or am I supposed to apply before the result ? ',\n",
              "       'What is it really like to be a nurse practitioner ? ', ...,\n",
              "       'Where I can find best friendship quotes in Telugu ? ',\n",
              "       'What are the causes of refraction of light ? ',\n",
              "       'Climate change is a worrying topic .  How much time do we have left to find another planet ?  I mean ,  I do not think humans will survive on this earth for another #### years .  .  What do you think ? '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1weXAE-t87q"
      },
      "source": [
        "max_word_per_sentence = 70\n",
        "test_padding = []\n",
        "for sentence in Test_X:\n",
        "  list2 =[]\n",
        "  for word in sentence.split():\n",
        "    try:\n",
        "      list2.append(dict_use[word])\n",
        "    except:\n",
        "      list2.append(dict_use[\"OOV\"])\n",
        "  test_padding.append(list2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUXG63l7uIhL"
      },
      "source": [
        "max_word_per_sentence = 70\n",
        "test_padding_maxword = []\n",
        "for i in test_padding:\n",
        "  sentence  = i.copy()\n",
        "  if len(i) > max_word_per_sentence:\n",
        "    test_padding_maxword.append(sentence[:max_word_per_sentence])\n",
        "  else:\n",
        "    for i in range(max_word_per_sentence-len(i)):\n",
        "      sentence.append(0)\n",
        "    test_padding_maxword.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-4M6CIv8QjC",
        "outputId": "1472e5f8-7a4c-4615-df06-56b90f3cffa0"
      },
      "source": [
        "for i in test_padding_maxword[:10]:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17, 13, 65, 86, 145, 117, 65, 1811, 11, 4111, 51, 55, 38, 120, 5, 787, 1653, 8, 2226, 11, 329, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[128, 50, 9, 394, 15, 10606, 181, 8, 195, 11, 7581, 181, 8, 195, 1, 116, 9, 1568, 15, 2, 3980, 997, 27, 73, 9, 1611, 4, 394, 163, 2, 997, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[3, 7, 18, 152, 49, 4, 28, 5, 4570, 14149, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[93, 14, 3988, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[21, 499, 152, 377, 63, 44, 2340, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[10, 13, 16, 993, 5, 15675, 4, 762, 1581, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[3, 7, 2, 1709, 6, 40469, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[3, 7, 2, 275, 15, 13624, 12, 20, 2, 166, 944, 179, 1974, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[216, 1185, 1488, 7, 4280, 35, 7443, 19, 216, 2468, 1185, 1322, 104, 4, 3720, 19, 49863, 3263, 6, 23, 830, 2468, 1488, 19, 3, 7, 23, 1185, 339, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[10, 91, 32, 5, 7622, 588, 6, 611, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl5g1U1Sfv5S",
        "outputId": "026e5f08-7b27-4803-9908-bd8256507311"
      },
      "source": [
        "len(test_padding_maxword)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIt4l_emuIjb"
      },
      "source": [
        "y_predict_glove = new_model.predict(np.array(test_padding_maxword))\n",
        "y_predict_fasttext = new_model2.predict(np.array(test_padding_maxword))\n",
        "y_predict_paragram = new_model3.predict(np.array(test_padding_maxword))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMKXwb7mwvMV"
      },
      "source": [
        "#Case1 Average case\n",
        "Coefficient_Glove = 0.33\n",
        "Coefficient_Fasttext =0.33\n",
        "Coefficient_Paragram = 0.34\n",
        "y_predict_proba1 = Coefficient_Glove*y_predict_glove + Coefficient_Fasttext*y_predict_fasttext + Coefficient_Paragram*y_predict_paragram\n",
        "submission_1 = pd.DataFrame(y_predict_proba1,columns=[\"Y_prediction_Proba\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Xdzuc7QMfer7",
        "outputId": "adc49463-4dab-46d3-cb29-6f68496d7a0e"
      },
      "source": [
        "submission_to_answer = pd.read_csv(\"submission/sample_submission.csv\")\n",
        "submission_to_answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375801</th>\n",
              "      <td>ffff7fa746bd6d6197a9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375802</th>\n",
              "      <td>ffffa1be31c43046ab6b</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375803</th>\n",
              "      <td>ffffae173b6ca6bfa563</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375804</th>\n",
              "      <td>ffffb1f7f1a008620287</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375805</th>\n",
              "      <td>fffff85473f4699474b0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>375806 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         qid  prediction\n",
              "0       0000163e3ea7c7a74cd7           0\n",
              "1       00002bd4fb5d505b9161           0\n",
              "2       00007756b4a147d2b0b3           0\n",
              "3       000086e4b7e1c7146103           0\n",
              "4       0000c4c3fbe8785a3090           0\n",
              "...                      ...         ...\n",
              "375801  ffff7fa746bd6d6197a9           0\n",
              "375802  ffffa1be31c43046ab6b           0\n",
              "375803  ffffae173b6ca6bfa563           0\n",
              "375804  ffffb1f7f1a008620287           0\n",
              "375805  fffff85473f4699474b0           0\n",
              "\n",
              "[375806 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7WK4sCldekS"
      },
      "source": [
        "decision_boundary = 38 #for the first submission case\n",
        "submission_1[\"Y_test_Predict\"] = np.where(submission_1.Y_prediction_Proba >= decision_boundary/100,1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "w_4L9PJbegBq",
        "outputId": "9c44fcb5-a9b2-4625-92b3-a9a88fc137c6"
      },
      "source": [
        "submission_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_prediction_Proba</th>\n",
              "      <th>Y_test_Predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.809963</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000193</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000149</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000194</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005191</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375801</th>\n",
              "      <td>0.000195</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375802</th>\n",
              "      <td>0.000246</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375803</th>\n",
              "      <td>0.000766</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375804</th>\n",
              "      <td>0.000031</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375805</th>\n",
              "      <td>0.035566</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>375806 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Y_prediction_Proba  Y_test_Predict\n",
              "0                 0.809963               1\n",
              "1                 0.000193               0\n",
              "2                 0.000149               0\n",
              "3                 0.000194               0\n",
              "4                 0.005191               0\n",
              "...                    ...             ...\n",
              "375801            0.000195               0\n",
              "375802            0.000246               0\n",
              "375803            0.000766               0\n",
              "375804            0.000031               0\n",
              "375805            0.035566               0\n",
              "\n",
              "[375806 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKNg-G5VuImG"
      },
      "source": [
        "#Case 2 Optimization case\n",
        "Coefficient_Glove = list_ab[0][0]\n",
        "Coefficient_Fasttext = list_ab[0][1]\n",
        "Coefficient_Paragram = list_ab[0][2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnwXQRqUuIok"
      },
      "source": [
        "y_predict_proba2 = Coefficient_Glove*y_predict_glove + Coefficient_Fasttext*y_predict_fasttext + Coefficient_Paragram*y_predict_paragram\n",
        "submission_2 = pd.DataFrame(y_predict_proba2,columns=[\"Y_prediction_Proba\"])\n",
        "decision_boundary2 = list_ab[1]\n",
        "submission_2[\"Y_test_Predict\"] = np.where(submission_2.Y_prediction_Proba >= decision_boundary2/100,1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "YDPlWsLWfDrb",
        "outputId": "c9f6a3db-033d-4acd-e450-b42cad4cdea7"
      },
      "source": [
        "submission_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_prediction_Proba</th>\n",
              "      <th>Y_test_Predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.809210</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000195</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000190</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005068</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375801</th>\n",
              "      <td>0.000159</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375802</th>\n",
              "      <td>0.000213</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375803</th>\n",
              "      <td>0.000746</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375804</th>\n",
              "      <td>0.000028</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375805</th>\n",
              "      <td>0.038802</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>375806 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Y_prediction_Proba  Y_test_Predict\n",
              "0                 0.809210               1\n",
              "1                 0.000195               0\n",
              "2                 0.000143               0\n",
              "3                 0.000190               0\n",
              "4                 0.005068               0\n",
              "...                    ...             ...\n",
              "375801            0.000159               0\n",
              "375802            0.000213               0\n",
              "375803            0.000746               0\n",
              "375804            0.000028               0\n",
              "375805            0.038802               0\n",
              "\n",
              "[375806 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgQ6vA8cx0WI"
      },
      "source": [
        "Answer in two submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q58RPcjjuIqd"
      },
      "source": [
        "submission_to_answer_case1 = submission_to_answer.copy()\n",
        "submission_to_answer_case1[\"prediction\"] = submission_1[\"Y_test_Predict\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bNQZOdEuIs8"
      },
      "source": [
        "submission_to_answer_case2 = submission_to_answer.copy()\n",
        "submission_to_answer_case2[\"prediction\"] = submission_2[\"Y_test_Predict\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol2WES8ht8_s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "4d2b5f8b-bc41-4482-97de-f38426645a0e"
      },
      "source": [
        "submission_2.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_prediction_Proba</th>\n",
              "      <th>Y_test_Predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.809210</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000195</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000190</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005068</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.009318</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000238</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000254</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000274</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000247</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000721</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000173</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.001458</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.019702</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000441</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Y_prediction_Proba  Y_test_Predict\n",
              "0             0.809210               1\n",
              "1             0.000195               0\n",
              "2             0.000143               0\n",
              "3             0.000190               0\n",
              "4             0.005068               0\n",
              "5             0.009318               0\n",
              "6             0.000238               0\n",
              "7             0.000254               0\n",
              "8             0.000274               0\n",
              "9             0.000247               0\n",
              "10            0.000721               0\n",
              "11            0.000173               0\n",
              "12            0.001458               0\n",
              "13            0.019702               0\n",
              "14            0.000441               0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "8zFbBhXghVHI",
        "outputId": "a5409df0-39dc-4176-8bf6-e3263929fdaa"
      },
      "source": [
        "submission_1.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_prediction_Proba</th>\n",
              "      <th>Y_test_Predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.809963</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000193</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000149</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000194</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005191</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.008912</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000252</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000263</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000311</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000276</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000752</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000192</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.001515</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.018620</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000483</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Y_prediction_Proba  Y_test_Predict\n",
              "0             0.809963               1\n",
              "1             0.000193               0\n",
              "2             0.000149               0\n",
              "3             0.000194               0\n",
              "4             0.005191               0\n",
              "5             0.008912               0\n",
              "6             0.000252               0\n",
              "7             0.000263               0\n",
              "8             0.000311               0\n",
              "9             0.000276               0\n",
              "10            0.000752               0\n",
              "11            0.000192               0\n",
              "12            0.001515               0\n",
              "13            0.018620               0\n",
              "14            0.000483               0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "rtcQUzhChW_3",
        "outputId": "597b146c-5c13-4d46-d07d-21783921f93b"
      },
      "source": [
        "submission_to_answer_case1.to_csv(\"Submission1.csv\",index=False)\n",
        "submission_to_answer_case1.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>000101884c19f3515c1a</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>00010f62537781f44a47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00012afbd27452239059</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00014894849d00ba98a9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>000156468431f09b3cae</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>00015c487b65d0f79cd8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0001880504d9d091c8c8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>00019b780e31adab8acd</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0001d5bbc5f7b7a5ae58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0001f64b6aaf396c4cc4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     qid  prediction\n",
              "0   0000163e3ea7c7a74cd7           1\n",
              "1   00002bd4fb5d505b9161           0\n",
              "2   00007756b4a147d2b0b3           0\n",
              "3   000086e4b7e1c7146103           0\n",
              "4   0000c4c3fbe8785a3090           0\n",
              "5   000101884c19f3515c1a           0\n",
              "6   00010f62537781f44a47           0\n",
              "7   00012afbd27452239059           0\n",
              "8   00014894849d00ba98a9           0\n",
              "9   000156468431f09b3cae           0\n",
              "10  00015c487b65d0f79cd8           0\n",
              "11  0001880504d9d091c8c8           0\n",
              "12  00019b780e31adab8acd           0\n",
              "13  0001d5bbc5f7b7a5ae58           0\n",
              "14  0001f64b6aaf396c4cc4           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "Ud0oVfw2hlrQ",
        "outputId": "4911d6b6-1b2f-40da-a8cc-cd1bcec55500"
      },
      "source": [
        "submission_to_answer_case2.to_csv(\"Submission2.csv\",index=False)\n",
        "submission_to_answer_case2.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>000101884c19f3515c1a</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>00010f62537781f44a47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00012afbd27452239059</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00014894849d00ba98a9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>000156468431f09b3cae</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>00015c487b65d0f79cd8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0001880504d9d091c8c8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>00019b780e31adab8acd</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0001d5bbc5f7b7a5ae58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0001f64b6aaf396c4cc4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     qid  prediction\n",
              "0   0000163e3ea7c7a74cd7           1\n",
              "1   00002bd4fb5d505b9161           0\n",
              "2   00007756b4a147d2b0b3           0\n",
              "3   000086e4b7e1c7146103           0\n",
              "4   0000c4c3fbe8785a3090           0\n",
              "5   000101884c19f3515c1a           0\n",
              "6   00010f62537781f44a47           0\n",
              "7   00012afbd27452239059           0\n",
              "8   00014894849d00ba98a9           0\n",
              "9   000156468431f09b3cae           0\n",
              "10  00015c487b65d0f79cd8           0\n",
              "11  0001880504d9d091c8c8           0\n",
              "12  00019b780e31adab8acd           0\n",
              "13  0001d5bbc5f7b7a5ae58           0\n",
              "14  0001f64b6aaf396c4cc4           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3KMOf7ChluG"
      },
      "source": [
        "submission_to_answer_case2.to_csv(\"Submission_Optimizing.csv\",index=False)\n",
        "file.downlaod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el51jibehlwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "0593b001-edf4-421a-b3e3-f4488a6927a2"
      },
      "source": [
        "submission_to_answer_case1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375801</th>\n",
              "      <td>ffff7fa746bd6d6197a9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375802</th>\n",
              "      <td>ffffa1be31c43046ab6b</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375803</th>\n",
              "      <td>ffffae173b6ca6bfa563</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375804</th>\n",
              "      <td>ffffb1f7f1a008620287</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375805</th>\n",
              "      <td>fffff85473f4699474b0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>375806 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         qid  prediction\n",
              "0       0000163e3ea7c7a74cd7           1\n",
              "1       00002bd4fb5d505b9161           0\n",
              "2       00007756b4a147d2b0b3           0\n",
              "3       000086e4b7e1c7146103           0\n",
              "4       0000c4c3fbe8785a3090           0\n",
              "...                      ...         ...\n",
              "375801  ffff7fa746bd6d6197a9           0\n",
              "375802  ffffa1be31c43046ab6b           0\n",
              "375803  ffffae173b6ca6bfa563           0\n",
              "375804  ffffb1f7f1a008620287           0\n",
              "375805  fffff85473f4699474b0           0\n",
              "\n",
              "[375806 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_DRC5fChlyf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_IJ8CaZhl_i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgmKXg8_hmH0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
